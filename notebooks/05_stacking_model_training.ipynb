{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34cea203-4756-4f22-a752-1011c3ff050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95fb318-3640-4c85-ac20-b1f9cef4697b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/BigDataProject'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/home/ubuntu/BigDataProject\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f784f4-5161-47f0-b5c4-f648799dfa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-07 11:29:11,141: 47: logger: INFO: common:  yaml file: src/config/config.yaml loaded successfully]\n",
      "[2024-01-07 11:29:11,144: 47: logger: INFO: common:  yaml file: src/params.yaml loaded successfully]\n",
      "[2024-01-07 11:29:11,146: 47: logger: INFO: common:  yaml file: src/schema.yaml loaded successfully]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingModelTrainingConfig(embedding_file_size=51200, min_train_embedding_id=2, max_train_embedding_id=85, head_models=BoxList(['MHSA_STCNN_GRU', 'MHSA_STCNN_BiRNN', 'MHSA_STCNN_BiLSTM']), models=BoxList(['LogisticRegression']), scoring_metric='f1', swap_labels=True, n_folds=4, n_jobs=-1, random_state=42, optimization_direction='maximize', n_trials=100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.config.configuration import ConfigurationManager\n",
    "from src.components.stacking_model_training import StackingModelTraining\n",
    "\n",
    "config_manager = ConfigurationManager()\n",
    "stacking_model_training_config = config_manager.get_stacking_model_training_config()\n",
    "\n",
    "stacking_model_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c52ad74-845d-4dc1-9554-e2dd0c349345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-07 11:29:11,158: 47: logger: INFO: common:  yaml file: src/params/LGBMClassifier.yaml loaded successfully]\n",
      "[2024-01-07 11:29:11,159: 175: logger: INFO: stacking_model_training:  === STARTING TRAINING STAGE for stacking models ===]\n",
      "[2024-01-07 11:29:11,196: 171: logger: INFO: common:  tensor file has been loaded from: data/target]\n",
      "[2024-01-07 11:29:13,484: 179: logger: INFO: stacking_model_training:  Part1. Target data has been loaded]\n",
      "[2024-01-07 11:29:13,603: 184: logger: INFO: stacking_model_training:  Part2. First level logits have been loaded]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b05e7f3d464380838308cb835176d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tuning Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 11:29:13,611] A new study created in memory with name: no-name-0b46dfd1-0c4d-48fe-b91c-e37db9e9de07\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:29:58,877] Trial 0 finished with value: 0.8211191271812531 and parameters: {'learning_rate': 0.013292918943162165, 'min_data_in_leaf': 956, 'num_leaves': 7, 'max_depth': 1, 'bagging_fraction': 0.5290418060840998, 'bagging_freq': 18, 'reg_lambda': 0.4042872735027334, 'reg_alpha': 1.7718847354806828}. Best is trial 0 with value: 0.8211191271812531.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:30:45,503] Trial 1 finished with value: 0.0 and parameters: {'learning_rate': 0.00115279871282324, 'min_data_in_leaf': 973, 'num_leaves': 7, 'max_depth': 1, 'bagging_fraction': 0.6521211214797689, 'bagging_freq': 13, 'reg_lambda': 0.039054412752107935, 'reg_alpha': 0.005589524205217926}. Best is trial 0 with value: 0.8211191271812531.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:32:21,385] Trial 2 finished with value: 0.8220069957737283 and parameters: {'learning_rate': 0.06847920095574778, 'min_data_in_leaf': 225, 'num_leaves': 4, 'max_depth': 3, 'bagging_fraction': 0.5998368910791798, 'bagging_freq': 13, 'reg_lambda': 0.35849855803404745, 'reg_alpha': 0.0001899776347411129}. Best is trial 2 with value: 0.8220069957737283.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:33:09,541] Trial 3 finished with value: 0.8228899780505876 and parameters: {'learning_rate': 0.06647135865318027, 'min_data_in_leaf': 253, 'num_leaves': 2, 'max_depth': 2, 'bagging_fraction': 0.6523068845866853, 'bagging_freq': 6, 'reg_lambda': 1.274671157821506, 'reg_alpha': 0.04374364439939081}. Best is trial 3 with value: 0.8228899780505876.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:33:55,162] Trial 4 finished with value: 0.0 and parameters: {'learning_rate': 0.002323350351539011, 'min_data_in_leaf': 546, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6558555380447055, 'bagging_freq': 13, 'reg_lambda': 0.1906609163818847, 'reg_alpha': 0.0012856617791467942}. Best is trial 3 with value: 0.8228899780505876.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:36:20,030] Trial 5 finished with value: 0.8209819561975098 and parameters: {'learning_rate': 0.8105016126411579, 'min_data_in_leaf': 798, 'num_leaves': 8, 'max_depth': 3, 'bagging_fraction': 0.5442462510259598, 'bagging_freq': 8, 'reg_lambda': 0.00018679434894556328, 'reg_alpha': 0.008953276247642715}. Best is trial 3 with value: 0.8228899780505876.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=253, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=253\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6523068845866853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6523068845866853\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=253, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6523068845866853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6523068845866853\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.210687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=253, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6523068845866853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6523068845866853\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=253, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=253\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6523068845866853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6523068845866853\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=253, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6523068845866853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6523068845866853\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.211433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=253, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6523068845866853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6523068845866853\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=253, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=253\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6523068845866853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6523068845866853\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=253, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6523068845866853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6523068845866853\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=253, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6523068845866853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6523068845866853\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=253, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=253\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6523068845866853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6523068845866853\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=253, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6523068845866853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6523068845866853\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=253, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6523068845866853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6523068845866853\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 11:38:36,959] Trial 6 finished with value: 0.8147490937459818 and parameters: {'learning_rate': 0.014656553886225332, 'min_data_in_leaf': 344, 'num_leaves': 7, 'max_depth': 3, 'bagging_fraction': 0.5704621124873813, 'bagging_freq': 17, 'reg_lambda': 0.00028009403633756793, 'reg_alpha': 83.4298801304735}. Best is trial 3 with value: 0.8228899780505876.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:39:23,906] Trial 7 finished with value: 0.8231374350263538 and parameters: {'learning_rate': 0.2073644517790503, 'min_data_in_leaf': 279, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.8856351733429728, 'bagging_freq': 6, 'reg_lambda': 0.014151235919053715, 'reg_alpha': 0.0004956947932799964}. Best is trial 7 with value: 0.8231374350263538.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:41:00,516] Trial 8 finished with value: 0.8211456376051286 and parameters: {'learning_rate': 0.3884277754703141, 'min_data_in_leaf': 661, 'num_leaves': 4, 'max_depth': 3, 'bagging_fraction': 0.864803089169032, 'bagging_freq': 15, 'reg_lambda': 21.051180519608735, 'reg_alpha': 0.06812233896860301}. Best is trial 7 with value: 0.8231374350263538.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:42:24,342] Trial 9 finished with value: 0.0 and parameters: {'learning_rate': 0.0022844556850020537, 'min_data_in_leaf': 742, 'num_leaves': 7, 'max_depth': 2, 'bagging_fraction': 0.7613664146909971, 'bagging_freq': 11, 'reg_lambda': 0.00014207404990676056, 'reg_alpha': 0.00044396482429275296}. Best is trial 7 with value: 0.8231374350263538.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:43:16,548] Trial 10 finished with value: 0.8230737603503685 and parameters: {'learning_rate': 0.21464035477145846, 'min_data_in_leaf': 105, 'num_leaves': 4, 'max_depth': 1, 'bagging_fraction': 0.9896117410993797, 'bagging_freq': 5, 'reg_lambda': 0.0035282692168192176, 'reg_alpha': 1.3799038932042031}. Best is trial 7 with value: 0.8231374350263538.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:44:07,792] Trial 11 finished with value: 0.8228969722356724 and parameters: {'learning_rate': 0.22433077847887195, 'min_data_in_leaf': 103, 'num_leaves': 4, 'max_depth': 1, 'bagging_fraction': 0.9867714017984972, 'bagging_freq': 5, 'reg_lambda': 0.005713624957706178, 'reg_alpha': 2.2157998549309914}. Best is trial 7 with value: 0.8231374350263538.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=973, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=973\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6521211214797689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6521211214797689\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=973, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6521211214797689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6521211214797689\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=973, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6521211214797689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6521211214797689\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5442462510259598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5442462510259598\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5442462510259598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5442462510259598\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5442462510259598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5442462510259598\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=661, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=661\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864803089169032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864803089169032\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=661, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=661\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864803089169032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864803089169032\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.142353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=661, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=661\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864803089169032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864803089169032\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9817470074514311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9817470074514311\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9817470074514311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9817470074514311\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=973, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=973\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6521211214797689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6521211214797689\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=973, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6521211214797689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6521211214797689\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.190608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=973, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6521211214797689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6521211214797689\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5442462510259598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5442462510259598\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5442462510259598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5442462510259598\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.157483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5442462510259598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5442462510259598\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=661, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=661\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864803089169032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864803089169032\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=661, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=661\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864803089169032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864803089169032\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=661, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=661\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864803089169032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864803089169032\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9817470074514311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9817470074514311\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9817470074514311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9817470074514311\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=973, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=973\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6521211214797689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6521211214797689\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=973, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6521211214797689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6521211214797689\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=973, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6521211214797689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6521211214797689\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5442462510259598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5442462510259598\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5442462510259598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5442462510259598\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5442462510259598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5442462510259598\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=661, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=661\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864803089169032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864803089169032\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=661, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=661\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864803089169032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864803089169032\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.195121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=661, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=661\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864803089169032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864803089169032\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9817470074514311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9817470074514311\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9817470074514311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9817470074514311\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.230744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=973, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=973\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6521211214797689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6521211214797689\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=973, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6521211214797689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6521211214797689\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=973, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6521211214797689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6521211214797689\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5442462510259598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5442462510259598\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5442462510259598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5442462510259598\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5442462510259598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5442462510259598\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=661, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=661\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864803089169032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864803089169032\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=661, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=661\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864803089169032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864803089169032\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.184830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=661, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=661\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.864803089169032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.864803089169032\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9817470074514311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9817470074514311\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9817470074514311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9817470074514311\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.148284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 11:44:57,023] Trial 12 finished with value: 0.8217411984048326 and parameters: {'learning_rate': 0.15317382302559174, 'min_data_in_leaf': 471, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.9817470074514311, 'bagging_freq': 8, 'reg_lambda': 0.0036831373722294634, 'reg_alpha': 1.1505575551691578}. Best is trial 7 with value: 0.8231374350263538.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:45:45,172] Trial 13 finished with value: 0.8215616573316173 and parameters: {'learning_rate': 0.8745056085259909, 'min_data_in_leaf': 130, 'num_leaves': 5, 'max_depth': 1, 'bagging_fraction': 0.8881655280019187, 'bagging_freq': 9, 'reg_lambda': 0.008394504330199781, 'reg_alpha': 34.085537152320505}. Best is trial 7 with value: 0.8231374350263538.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:46:34,610] Trial 14 finished with value: 0.8231097256991122 and parameters: {'learning_rate': 0.08129948297847955, 'min_data_in_leaf': 387, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.8889516849989578, 'bagging_freq': 5, 'reg_lambda': 0.0012928806520955192, 'reg_alpha': 0.3687708531058646}. Best is trial 7 with value: 0.8231374350263538.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=956, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=956\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5290418060840998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5290418060840998\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=956, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=956\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5290418060840998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5290418060840998\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.167933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=956, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=956\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5290418060840998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5290418060840998\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=546, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=546\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6558555380447055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6558555380447055\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=546, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6558555380447055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6558555380447055\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=546, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6558555380447055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6558555380447055\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=279, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=279\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8856351733429728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8856351733429728\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=279, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8856351733429728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8856351733429728\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=279, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8856351733429728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8856351733429728\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9867714017984972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9867714017984972\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9867714017984972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9867714017984972\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.207288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9867714017984972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9867714017984972\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=389, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=389\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524635413007553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524635413007553\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=389, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524635413007553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524635413007553\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.213242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=956, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=956\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5290418060840998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5290418060840998\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=956, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=956\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5290418060840998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5290418060840998\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=956, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=956\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5290418060840998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5290418060840998\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=546, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=546\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6558555380447055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6558555380447055\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=546, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6558555380447055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6558555380447055\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=546, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6558555380447055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6558555380447055\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=279, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=279\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8856351733429728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8856351733429728\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=279, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8856351733429728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8856351733429728\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.245577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=279, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8856351733429728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8856351733429728\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9867714017984972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9867714017984972\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9867714017984972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9867714017984972\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.232421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9867714017984972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9867714017984972\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=389, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=389\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524635413007553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524635413007553\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=389, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524635413007553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524635413007553\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.259056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=956, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=956\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5290418060840998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5290418060840998\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=956, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=956\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5290418060840998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5290418060840998\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=956, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=956\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5290418060840998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5290418060840998\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=546, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=546\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6558555380447055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6558555380447055\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=546, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6558555380447055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6558555380447055\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=546, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6558555380447055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6558555380447055\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=279, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=279\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8856351733429728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8856351733429728\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=279, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8856351733429728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8856351733429728\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=279, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8856351733429728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8856351733429728\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9867714017984972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9867714017984972\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9867714017984972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9867714017984972\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.236483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9867714017984972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9867714017984972\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=389, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=389\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524635413007553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524635413007553\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=389, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524635413007553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524635413007553\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.235147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=956, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=956\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5290418060840998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5290418060840998\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=956, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=956\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5290418060840998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5290418060840998\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.185021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=956, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=956\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5290418060840998, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5290418060840998\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=546, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=546\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6558555380447055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6558555380447055\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=546, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6558555380447055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6558555380447055\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=546, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6558555380447055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6558555380447055\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=279, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=279\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8856351733429728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8856351733429728\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=279, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8856351733429728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8856351733429728\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.230389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=279, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8856351733429728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8856351733429728\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9867714017984972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9867714017984972\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9867714017984972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9867714017984972\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9867714017984972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9867714017984972\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=389, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=389\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524635413007553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524635413007553\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=389, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524635413007553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524635413007553\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 11:47:22,639] Trial 15 finished with value: 0.8228687563720665 and parameters: {'learning_rate': 0.051008583681790114, 'min_data_in_leaf': 389, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.8524635413007553, 'bagging_freq': 10, 'reg_lambda': 0.03434337205321073, 'reg_alpha': 0.2636432113274281}. Best is trial 7 with value: 0.8231374350263538.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:48:34,228] Trial 16 finished with value: 0.8170109342920858 and parameters: {'learning_rate': 0.014615444351755416, 'min_data_in_leaf': 379, 'num_leaves': 3, 'max_depth': 2, 'bagging_fraction': 0.770666431664493, 'bagging_freq': 20, 'reg_lambda': 0.0010934217312268478, 'reg_alpha': 0.004469344389070038}. Best is trial 7 with value: 0.8231374350263538.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=225, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=225\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5998368910791798, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5998368910791798\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=225, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=225\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5998368910791798, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5998368910791798\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.188663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=225, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=225\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5998368910791798, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5998368910791798\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=344, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=344\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5704621124873813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5704621124873813\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=344, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5704621124873813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5704621124873813\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.215431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=344, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5704621124873813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5704621124873813\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=742, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=742\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7613664146909971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7613664146909971\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=742, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=742\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7613664146909971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7613664146909971\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.245522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=742, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=742\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7613664146909971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7613664146909971\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881655280019187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8881655280019187\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881655280019187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8881655280019187\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.172749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881655280019187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8881655280019187\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=503, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=503\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099202406509211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099202406509211\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=503, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=503\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099202406509211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099202406509211\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.210359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=225, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=225\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5998368910791798, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5998368910791798\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=225, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=225\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5998368910791798, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5998368910791798\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.156718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=225, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=225\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5998368910791798, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5998368910791798\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=344, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=344\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5704621124873813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5704621124873813\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=344, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5704621124873813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5704621124873813\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=344, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5704621124873813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5704621124873813\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=742, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=742\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7613664146909971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7613664146909971\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=742, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=742\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7613664146909971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7613664146909971\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.233273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=742, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=742\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7613664146909971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7613664146909971\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881655280019187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8881655280019187\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881655280019187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8881655280019187\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881655280019187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8881655280019187\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=503, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=503\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099202406509211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099202406509211\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=503, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=503\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099202406509211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099202406509211\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.229364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=225, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=225\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5998368910791798, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5998368910791798\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=225, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=225\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5998368910791798, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5998368910791798\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.185040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=225, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=225\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5998368910791798, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5998368910791798\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=344, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=344\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5704621124873813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5704621124873813\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=344, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5704621124873813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5704621124873813\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.212330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=344, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5704621124873813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5704621124873813\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=742, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=742\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7613664146909971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7613664146909971\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=742, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=742\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7613664146909971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7613664146909971\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.212163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=742, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=742\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7613664146909971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7613664146909971\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881655280019187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8881655280019187\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881655280019187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8881655280019187\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881655280019187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8881655280019187\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=503, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=503\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099202406509211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099202406509211\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=503, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=503\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099202406509211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099202406509211\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.229856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=225, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=225\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5998368910791798, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5998368910791798\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=225, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=225\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5998368910791798, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5998368910791798\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.242630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=225, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=225\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5998368910791798, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5998368910791798\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=344, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=344\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5704621124873813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5704621124873813\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=344, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5704621124873813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5704621124873813\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=344, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5704621124873813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5704621124873813\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=742, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=742\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7613664146909971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7613664146909971\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=742, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=742\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7613664146909971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7613664146909971\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.259369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=742, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=742\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7613664146909971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7613664146909971\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881655280019187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8881655280019187\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881655280019187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8881655280019187\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881655280019187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8881655280019187\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=503, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=503\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099202406509211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099202406509211\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=503, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=503\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099202406509211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099202406509211\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 11:49:23,455] Trial 17 finished with value: 0.8222912956060566 and parameters: {'learning_rate': 0.028454261600331685, 'min_data_in_leaf': 503, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.9099202406509211, 'bagging_freq': 7, 'reg_lambda': 4.518032142648396, 'reg_alpha': 0.26580203898294863}. Best is trial 7 with value: 0.8231374350263538.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:50:12,417] Trial 18 finished with value: 0.8233153574808778 and parameters: {'learning_rate': 0.12208000277202244, 'min_data_in_leaf': 280, 'num_leaves': 5, 'max_depth': 1, 'bagging_fraction': 0.8073937618947272, 'bagging_freq': 11, 'reg_lambda': 0.030514494837155345, 'reg_alpha': 6.009967640743969}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:51:35,617] Trial 19 finished with value: 0.8203677140423543 and parameters: {'learning_rate': 0.41946462124573936, 'min_data_in_leaf': 250, 'num_leaves': 6, 'max_depth': 2, 'bagging_fraction': 0.8141106740609885, 'bagging_freq': 15, 'reg_lambda': 0.05305132296064149, 'reg_alpha': 7.841136674302283}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:52:22,145] Trial 20 finished with value: 0.8230584656644342 and parameters: {'learning_rate': 0.12000695018712274, 'min_data_in_leaf': 640, 'num_leaves': 5, 'max_depth': 1, 'bagging_fraction': 0.7142956443320208, 'bagging_freq': 11, 'reg_lambda': 0.01349435407326905, 'reg_alpha': 8.634755388493204}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:53:08,806] Trial 21 finished with value: 0.8226179795000851 and parameters: {'learning_rate': 0.10435131815656486, 'min_data_in_leaf': 306, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.9230359790079975, 'bagging_freq': 7, 'reg_lambda': 0.0008715772677335, 'reg_alpha': 0.024316652538611132}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:53:56,032] Trial 22 finished with value: 0.8223827830643574 and parameters: {'learning_rate': 0.030597043839291543, 'min_data_in_leaf': 439, 'num_leaves': 5, 'max_depth': 1, 'bagging_fraction': 0.8049508359702008, 'bagging_freq': 5, 'reg_lambda': 0.0010951018066380012, 'reg_alpha': 0.43643672855959953}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:54:42,241] Trial 23 finished with value: 0.8207292318914519 and parameters: {'learning_rate': 0.35632918778922607, 'min_data_in_leaf': 204, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.9312404495902853, 'bagging_freq': 7, 'reg_lambda': 0.02294740921373564, 'reg_alpha': 11.897238152491425}. Best is trial 18 with value: 0.8233153574808778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=389, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524635413007553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524635413007553\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8141106740609885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8141106740609885\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8141106740609885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8141106740609885\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8141106740609885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8141106740609885\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312404495902853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312404495902853\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312404495902853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312404495902853\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312404495902853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312404495902853\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:55:29,163] Trial 24 finished with value: 0.8228472495642446 and parameters: {'learning_rate': 0.04370396334239357, 'min_data_in_leaf': 318, 'num_leaves': 6, 'max_depth': 1, 'bagging_fraction': 0.844492539690197, 'bagging_freq': 9, 'reg_lambda': 0.0020168544399332506, 'reg_alpha': 0.151854048870182}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:56:15,478] Trial 25 finished with value: 0.8232413127860758 and parameters: {'learning_rate': 0.1103408147977492, 'min_data_in_leaf': 418, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.7305883778847562, 'bagging_freq': 11, 'reg_lambda': 0.07050547312650396, 'reg_alpha': 0.00010336829180361495}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=105, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=105\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9896117410993797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9896117410993797\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=105, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9896117410993797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9896117410993797\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.152926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=105, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9896117410993797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9896117410993797\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=387, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=387\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8889516849989578, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8889516849989578\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=387, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8889516849989578, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8889516849989578\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.211727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=387, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8889516849989578, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8889516849989578\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8073937618947272, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073937618947272\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8073937618947272, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073937618947272\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.237887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8073937618947272, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073937618947272\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8049508359702008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049508359702008\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8049508359702008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049508359702008\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.235110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8049508359702008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049508359702008\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7273703313340233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7273703313340233\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7273703313340233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7273703313340233\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.261862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=105, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=105\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9896117410993797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9896117410993797\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=105, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9896117410993797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9896117410993797\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=105, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9896117410993797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9896117410993797\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=387, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=387\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8889516849989578, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8889516849989578\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=387, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8889516849989578, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8889516849989578\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.177718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=387, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8889516849989578, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8889516849989578\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8073937618947272, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073937618947272\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8073937618947272, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073937618947272\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.192736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8073937618947272, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073937618947272\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8049508359702008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049508359702008\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8049508359702008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049508359702008\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.171448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8049508359702008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049508359702008\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7273703313340233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7273703313340233\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7273703313340233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7273703313340233\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.293838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=105, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=105\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9896117410993797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9896117410993797\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=105, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9896117410993797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9896117410993797\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.211072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=105, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9896117410993797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9896117410993797\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=387, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=387\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8889516849989578, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8889516849989578\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=387, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8889516849989578, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8889516849989578\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.198938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=387, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8889516849989578, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8889516849989578\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8073937618947272, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073937618947272\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8073937618947272, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073937618947272\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8073937618947272, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073937618947272\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8049508359702008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049508359702008\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8049508359702008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049508359702008\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.207480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8049508359702008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049508359702008\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7273703313340233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7273703313340233\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7273703313340233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7273703313340233\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=105, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=105\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9896117410993797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9896117410993797\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=105, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9896117410993797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9896117410993797\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.163001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=105, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9896117410993797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9896117410993797\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=387, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=387\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8889516849989578, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8889516849989578\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=387, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8889516849989578, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8889516849989578\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=387, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8889516849989578, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8889516849989578\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8073937618947272, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073937618947272\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8073937618947272, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073937618947272\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8073937618947272, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073937618947272\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8049508359702008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049508359702008\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8049508359702008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049508359702008\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.162228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=439, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=439\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8049508359702008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049508359702008\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7273703313340233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7273703313340233\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7273703313340233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7273703313340233\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 11:57:02,153] Trial 26 finished with value: 0.8231519457845902 and parameters: {'learning_rate': 0.21014958387497135, 'min_data_in_leaf': 178, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7273703313340233, 'bagging_freq': 11, 'reg_lambda': 0.09297081030806045, 'reg_alpha': 0.0001345487321666761}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:57:51,788] Trial 27 finished with value: 0.8215051855013139 and parameters: {'learning_rate': 0.4181472804262895, 'min_data_in_leaf': 160, 'num_leaves': 6, 'max_depth': 1, 'bagging_fraction': 0.7081569207548235, 'bagging_freq': 11, 'reg_lambda': 1.3485701479012364, 'reg_alpha': 0.00010128657199833157}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 11:59:14,438] Trial 28 finished with value: 0.7760525799155413 and parameters: {'learning_rate': 0.006962964489408693, 'min_data_in_leaf': 174, 'num_leaves': 5, 'max_depth': 2, 'bagging_fraction': 0.7173542767062685, 'bagging_freq': 12, 'reg_lambda': 0.10591319683075844, 'reg_alpha': 0.0011628334661060516}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:00:27,367] Trial 29 finished with value: 0.8223276807334894 and parameters: {'learning_rate': 0.15554329757887997, 'min_data_in_leaf': 603, 'num_leaves': 3, 'max_depth': 3, 'bagging_fraction': 0.8041859363210639, 'bagging_freq': 15, 'reg_lambda': 0.6209246635507059, 'reg_alpha': 0.0017938992942853453}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:01:13,400] Trial 30 finished with value: 0.8220242226848709 and parameters: {'learning_rate': 0.02228973638630167, 'min_data_in_leaf': 888, 'num_leaves': 8, 'max_depth': 1, 'bagging_fraction': 0.7407527995752111, 'bagging_freq': 14, 'reg_lambda': 4.331628433642204, 'reg_alpha': 0.00011151654746987607}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:02:00,291] Trial 31 finished with value: 0.8232458042789291 and parameters: {'learning_rate': 0.24137422671718534, 'min_data_in_leaf': 263, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6772257548211985, 'bagging_freq': 12, 'reg_lambda': 0.09167539669334156, 'reg_alpha': 0.0005123030071082231}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.253626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9817470074514311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9817470074514311\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=379, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=379\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770666431664493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.770666431664493\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=379, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=379\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770666431664493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.770666431664493\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=379, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=379\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770666431664493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.770666431664493\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=640, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=640\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7142956443320208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7142956443320208\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=640, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=640\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7142956443320208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7142956443320208\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=640, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=640\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7142956443320208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7142956443320208\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=318, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=318\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.844492539690197, subsample=1.0 will be ignored. Current value: bagging_fraction=0.844492539690197\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=318, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=318\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.844492539690197, subsample=1.0 will be ignored. Current value: bagging_fraction=0.844492539690197\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.211626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=318, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=318\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.844492539690197, subsample=1.0 will be ignored. Current value: bagging_fraction=0.844492539690197\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=174, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=174\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7173542767062685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7173542767062685\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=174, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=174\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7173542767062685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7173542767062685\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.155404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=174, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=174\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7173542767062685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7173542767062685\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9817470074514311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9817470074514311\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=379, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=379\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770666431664493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.770666431664493\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=379, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=379\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770666431664493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.770666431664493\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.262741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=379, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=379\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770666431664493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.770666431664493\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=640, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=640\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7142956443320208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7142956443320208\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=640, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=640\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7142956443320208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7142956443320208\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=640, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=640\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7142956443320208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7142956443320208\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=318, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=318\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.844492539690197, subsample=1.0 will be ignored. Current value: bagging_fraction=0.844492539690197\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=318, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=318\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.844492539690197, subsample=1.0 will be ignored. Current value: bagging_fraction=0.844492539690197\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=318, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=318\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.844492539690197, subsample=1.0 will be ignored. Current value: bagging_fraction=0.844492539690197\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=174, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=174\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7173542767062685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7173542767062685\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=174, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=174\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7173542767062685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7173542767062685\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.210415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=174, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=174\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7173542767062685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7173542767062685\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9817470074514311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9817470074514311\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=379, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=379\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770666431664493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.770666431664493\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=379, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=379\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770666431664493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.770666431664493\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.240609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=379, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=379\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770666431664493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.770666431664493\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=640, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=640\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7142956443320208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7142956443320208\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=640, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=640\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7142956443320208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7142956443320208\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=640, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=640\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7142956443320208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7142956443320208\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=318, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=318\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.844492539690197, subsample=1.0 will be ignored. Current value: bagging_fraction=0.844492539690197\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=318, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=318\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.844492539690197, subsample=1.0 will be ignored. Current value: bagging_fraction=0.844492539690197\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=318, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=318\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.844492539690197, subsample=1.0 will be ignored. Current value: bagging_fraction=0.844492539690197\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=174, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=174\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7173542767062685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7173542767062685\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=174, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=174\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7173542767062685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7173542767062685\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=174, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=174\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7173542767062685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7173542767062685\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6784839644532631, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6784839644532631\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6784839644532631, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6784839644532631\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9817470074514311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9817470074514311\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=379, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=379\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770666431664493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.770666431664493\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=379, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=379\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770666431664493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.770666431664493\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=379, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=379\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770666431664493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.770666431664493\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=640, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=640\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7142956443320208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7142956443320208\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=640, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=640\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7142956443320208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7142956443320208\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.267380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=640, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=640\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7142956443320208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7142956443320208\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=318, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=318\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.844492539690197, subsample=1.0 will be ignored. Current value: bagging_fraction=0.844492539690197\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=318, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=318\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.844492539690197, subsample=1.0 will be ignored. Current value: bagging_fraction=0.844492539690197\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.266080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=318, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=318\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.844492539690197, subsample=1.0 will be ignored. Current value: bagging_fraction=0.844492539690197\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=174, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=174\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7173542767062685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7173542767062685\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=174, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=174\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7173542767062685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7173542767062685\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.231686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=174, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=174\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7173542767062685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7173542767062685\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6784839644532631, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6784839644532631\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:02:46,592] Trial 32 finished with value: 0.8215097282663679 and parameters: {'learning_rate': 0.5870406565077706, 'min_data_in_leaf': 215, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6784839644532631, 'bagging_freq': 12, 'reg_lambda': 0.08584109204805246, 'reg_alpha': 0.0003030848235433781}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:03:33,191] Trial 33 finished with value: 0.8209308338897209 and parameters: {'learning_rate': 0.2921399821400916, 'min_data_in_leaf': 431, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6113228714013651, 'bagging_freq': 10, 'reg_lambda': 0.2358300521428121, 'reg_alpha': 0.0007907526421527273}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:04:21,604] Trial 34 finished with value: 0.8230223415459206 and parameters: {'learning_rate': 0.10212253913740812, 'min_data_in_leaf': 329, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.6819216098165568, 'bagging_freq': 10, 'reg_lambda': 0.0681651312147154, 'reg_alpha': 0.00023220658760856626}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=389, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524635413007553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524635413007553\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8141106740609885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8141106740609885\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8141106740609885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8141106740609885\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.207934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8141106740609885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8141106740609885\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312404495902853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312404495902853\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312404495902853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312404495902853\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.230088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312404495902853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312404495902853\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7081569207548235, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7081569207548235\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7081569207548235, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7081569207548235\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7081569207548235, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7081569207548235\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6772257548211985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6772257548211985\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6772257548211985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6772257548211985\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.182795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6772257548211985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6772257548211985\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=254, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=254\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229868825435052, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229868825435052\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=389, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524635413007553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524635413007553\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8141106740609885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8141106740609885\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8141106740609885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8141106740609885\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.174741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8141106740609885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8141106740609885\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312404495902853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312404495902853\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312404495902853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312404495902853\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.186603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312404495902853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312404495902853\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7081569207548235, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7081569207548235\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7081569207548235, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7081569207548235\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.172292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7081569207548235, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7081569207548235\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6772257548211985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6772257548211985\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6772257548211985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6772257548211985\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.243039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6772257548211985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6772257548211985\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=254, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=254\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229868825435052, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229868825435052\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=389, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8524635413007553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8524635413007553\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8141106740609885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8141106740609885\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8141106740609885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8141106740609885\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8141106740609885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8141106740609885\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312404495902853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312404495902853\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312404495902853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312404495902853\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.201754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=204, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312404495902853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312404495902853\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7081569207548235, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7081569207548235\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7081569207548235, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7081569207548235\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.139860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7081569207548235, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7081569207548235\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6772257548211985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6772257548211985\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6772257548211985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6772257548211985\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.173723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6772257548211985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6772257548211985\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=254, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=254\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229868825435052, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229868825435052\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:05:08,416] Trial 35 finished with value: 0.8229031962018434 and parameters: {'learning_rate': 0.15186371076133587, 'min_data_in_leaf': 254, 'num_leaves': 4, 'max_depth': 1, 'bagging_fraction': 0.6229868825435052, 'bagging_freq': 12, 'reg_lambda': 0.13157300049193388, 'reg_alpha': 0.002403914220280649}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:05:55,566] Trial 36 finished with value: 0.8218065924837543 and parameters: {'learning_rate': 0.6255960430225029, 'min_data_in_leaf': 177, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7395551215892824, 'bagging_freq': 14, 'reg_lambda': 0.6561755716064349, 'reg_alpha': 0.018460734487806732}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=503, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=503\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099202406509211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099202406509211\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9230359790079975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9230359790079975\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9230359790079975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9230359790079975\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9230359790079975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9230359790079975\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=418, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=418\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7305883778847562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7305883778847562\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=418, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=418\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7305883778847562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7305883778847562\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.240000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=418, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=418\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7305883778847562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7305883778847562\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=603, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=603\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041859363210639, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041859363210639\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=603, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=603\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041859363210639, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041859363210639\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.201502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=603, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=603\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041859363210639, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041859363210639\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=431, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=431\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6113228714013651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6113228714013651\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=431, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=431\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6113228714013651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6113228714013651\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.230199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=431, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=431\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6113228714013651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6113228714013651\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=512, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=512\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7680155261629938, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7680155261629938\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=503, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=503\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099202406509211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099202406509211\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9230359790079975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9230359790079975\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9230359790079975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9230359790079975\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.230402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9230359790079975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9230359790079975\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=418, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=418\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7305883778847562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7305883778847562\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=418, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=418\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7305883778847562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7305883778847562\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.248464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=418, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=418\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7305883778847562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7305883778847562\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=603, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=603\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041859363210639, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041859363210639\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=603, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=603\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041859363210639, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041859363210639\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=603, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=603\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041859363210639, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041859363210639\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=431, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=431\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6113228714013651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6113228714013651\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=431, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=431\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6113228714013651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6113228714013651\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.206308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=431, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=431\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6113228714013651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6113228714013651\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=512, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=512\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7680155261629938, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7680155261629938\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=503, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=503\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099202406509211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099202406509211\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9230359790079975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9230359790079975\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9230359790079975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9230359790079975\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9230359790079975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9230359790079975\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=418, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=418\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7305883778847562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7305883778847562\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=418, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=418\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7305883778847562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7305883778847562\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.213700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=418, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=418\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7305883778847562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7305883778847562\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=603, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=603\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041859363210639, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041859363210639\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=603, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=603\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041859363210639, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041859363210639\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=603, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=603\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041859363210639, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041859363210639\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=431, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=431\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6113228714013651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6113228714013651\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=431, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=431\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6113228714013651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6113228714013651\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=431, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=431\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6113228714013651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6113228714013651\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=512, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=512\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7680155261629938, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7680155261629938\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=503, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=503\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9099202406509211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099202406509211\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9230359790079975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9230359790079975\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9230359790079975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9230359790079975\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.271840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9230359790079975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9230359790079975\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=418, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=418\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7305883778847562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7305883778847562\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=418, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=418\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7305883778847562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7305883778847562\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.180522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=418, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=418\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7305883778847562, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7305883778847562\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=603, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=603\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041859363210639, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041859363210639\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=603, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=603\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041859363210639, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041859363210639\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.247599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=603, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=603\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8041859363210639, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041859363210639\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=431, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=431\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6113228714013651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6113228714013651\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=431, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=431\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6113228714013651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6113228714013651\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.198112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=431, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=431\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6113228714013651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6113228714013651\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=512, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=512\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7680155261629938, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7680155261629938\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:06:43,013] Trial 37 finished with value: 0.8231440603371658 and parameters: {'learning_rate': 0.05770150667827978, 'min_data_in_leaf': 512, 'num_leaves': 2, 'max_depth': 3, 'bagging_fraction': 0.7680155261629938, 'bagging_freq': 13, 'reg_lambda': 0.02737127596718286, 'reg_alpha': 0.00018571670799887258}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:07:28,771] Trial 38 finished with value: 0.8229887553335806 and parameters: {'learning_rate': 0.08432699262362378, 'min_data_in_leaf': 280, 'num_leaves': 4, 'max_depth': 1, 'bagging_fraction': 0.6810998227457783, 'bagging_freq': 17, 'reg_lambda': 0.3461052261683383, 'reg_alpha': 0.004030421855004815}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:08:16,584] Trial 39 finished with value: 0.8226232875540507 and parameters: {'learning_rate': 0.2560883445682888, 'min_data_in_leaf': 361, 'num_leaves': 2, 'max_depth': 2, 'bagging_fraction': 0.6406089351880103, 'bagging_freq': 9, 'reg_lambda': 1.223416693586576, 'reg_alpha': 0.0007871925814071461}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:09:29,897] Trial 40 finished with value: 0.8231485702609473 and parameters: {'learning_rate': 0.04147511092316861, 'min_data_in_leaf': 421, 'num_leaves': 3, 'max_depth': 3, 'bagging_fraction': 0.5861746909439679, 'bagging_freq': 14, 'reg_lambda': 76.44629216756363, 'reg_alpha': 0.011229872962344175}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:10:40,984] Trial 41 finished with value: 0.823161438534673 and parameters: {'learning_rate': 0.04005700084371941, 'min_data_in_leaf': 412, 'num_leaves': 3, 'max_depth': 3, 'bagging_fraction': 0.5769947539013572, 'bagging_freq': 14, 'reg_lambda': 22.50820681086186, 'reg_alpha': 0.010986212186201815}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:11:50,861] Trial 42 finished with value: 0.7961883337780362 and parameters: {'learning_rate': 0.009690000107272724, 'min_data_in_leaf': 288, 'num_leaves': 3, 'max_depth': 3, 'bagging_fraction': 0.5013705091614475, 'bagging_freq': 11, 'reg_lambda': 0.19530005251697594, 'reg_alpha': 0.0005023214043686844}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7081569207548235, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7081569207548235\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7081569207548235, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7081569207548235\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7081569207548235, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7081569207548235\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6772257548211985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6772257548211985\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6772257548211985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6772257548211985\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6772257548211985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6772257548211985\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=254, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=254\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229868825435052, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229868825435052\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=254, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229868825435052, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229868825435052\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=254, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229868825435052, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229868825435052\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=361, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=361\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6406089351880103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6406089351880103\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=361, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=361\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6406089351880103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6406089351880103\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=361, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=361\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6406089351880103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6406089351880103\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=570, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=570\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5566403547984045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5566403547984045\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=570, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=570\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5566403547984045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5566403547984045\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.173291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:12:37,248] Trial 43 finished with value: 0.8229684918581773 and parameters: {'learning_rate': 0.07046710902246171, 'min_data_in_leaf': 570, 'num_leaves': 2, 'max_depth': 3, 'bagging_fraction': 0.5566403547984045, 'bagging_freq': 13, 'reg_lambda': 0.016935258494257418, 'reg_alpha': 0.038303738607448325}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:14:11,348] Trial 44 finished with value: 0.8214616218869419 and parameters: {'learning_rate': 0.17454767843385052, 'min_data_in_leaf': 215, 'num_leaves': 4, 'max_depth': 3, 'bagging_fraction': 0.5273430107657299, 'bagging_freq': 16, 'reg_lambda': 0.05017243072839424, 'reg_alpha': 0.0001844191674820514}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:14:56,479] Trial 45 finished with value: 0.8221335908833949 and parameters: {'learning_rate': 0.02159025668734784, 'min_data_in_leaf': 473, 'num_leaves': 2, 'max_depth': 3, 'bagging_fraction': 0.7840602729336841, 'bagging_freq': 12, 'reg_lambda': 71.69437046872046, 'reg_alpha': 0.0004091963273670157}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7273703313340233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7273703313340233\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=888, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=888\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7407527995752111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7407527995752111\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=888, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7407527995752111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7407527995752111\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.212679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=888, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7407527995752111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7407527995752111\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=329, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=329\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6819216098165568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6819216098165568\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=329, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=329\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6819216098165568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6819216098165568\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.215776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=329, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=329\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6819216098165568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6819216098165568\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6810998227457783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6810998227457783\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6810998227457783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6810998227457783\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.188218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6810998227457783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6810998227457783\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=288, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=288\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5013705091614475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5013705091614475\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=288, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=288\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5013705091614475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5013705091614475\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.232222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=288, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=288\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5013705091614475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5013705091614475\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=319, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=319\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6591980415344468, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6591980415344468\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7273703313340233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7273703313340233\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=888, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=888\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7407527995752111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7407527995752111\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=888, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7407527995752111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7407527995752111\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.180881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=888, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7407527995752111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7407527995752111\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=329, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=329\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6819216098165568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6819216098165568\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=329, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=329\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6819216098165568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6819216098165568\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.141184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=329, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=329\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6819216098165568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6819216098165568\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6810998227457783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6810998227457783\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6810998227457783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6810998227457783\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6810998227457783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6810998227457783\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=288, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=288\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5013705091614475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5013705091614475\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=288, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=288\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5013705091614475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5013705091614475\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.233699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=288, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=288\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5013705091614475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5013705091614475\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=319, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=319\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6591980415344468, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6591980415344468\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7273703313340233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7273703313340233\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=888, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=888\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7407527995752111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7407527995752111\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=888, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7407527995752111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7407527995752111\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.180702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=888, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7407527995752111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7407527995752111\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=329, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=329\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6819216098165568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6819216098165568\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=329, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=329\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6819216098165568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6819216098165568\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.240814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=329, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=329\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6819216098165568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6819216098165568\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6810998227457783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6810998227457783\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6810998227457783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6810998227457783\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.179128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6810998227457783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6810998227457783\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=288, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=288\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5013705091614475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5013705091614475\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=288, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=288\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5013705091614475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5013705091614475\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.173557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=288, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=288\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5013705091614475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5013705091614475\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=319, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=319\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6591980415344468, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6591980415344468\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7273703313340233, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7273703313340233\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=888, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=888\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7407527995752111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7407527995752111\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=888, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7407527995752111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7407527995752111\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.238347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=888, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7407527995752111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7407527995752111\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=329, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=329\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6819216098165568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6819216098165568\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=329, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=329\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6819216098165568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6819216098165568\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.273243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=329, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=329\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6819216098165568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6819216098165568\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6810998227457783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6810998227457783\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6810998227457783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6810998227457783\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.190520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=280, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=280\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6810998227457783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6810998227457783\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=288, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=288\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5013705091614475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5013705091614475\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=288, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=288\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5013705091614475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5013705091614475\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.189068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=288, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=288\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5013705091614475, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5013705091614475\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=319, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=319\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6591980415344468, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6591980415344468\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:15:40,756] Trial 46 finished with value: 0.8227993045251193 and parameters: {'learning_rate': 0.12229626343542403, 'min_data_in_leaf': 319, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.6591980415344468, 'bagging_freq': 13, 'reg_lambda': 5.184765467948869, 'reg_alpha': 0.008889533427704424}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:16:25,566] Trial 47 finished with value: 0.8210679760283401 and parameters: {'learning_rate': 0.29403481386826175, 'min_data_in_leaf': 263, 'num_leaves': 4, 'max_depth': 1, 'bagging_fraction': 0.7386015279171004, 'bagging_freq': 10, 'reg_lambda': 17.266415666815156, 'reg_alpha': 92.42970356773971}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6784839644532631, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6784839644532631\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6784839644532631, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6784839644532631\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.211209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6784839644532631, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6784839644532631\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=177, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=177\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7395551215892824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7395551215892824\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=177, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7395551215892824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7395551215892824\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.240961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=177, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7395551215892824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7395551215892824\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861746909439679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5861746909439679\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861746909439679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5861746909439679\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.179847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861746909439679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5861746909439679\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5273430107657299, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5273430107657299\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5273430107657299, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5273430107657299\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5273430107657299, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5273430107657299\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8307158906254093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8307158906254093\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8307158906254093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8307158906254093\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6784839644532631, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6784839644532631\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6784839644532631, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6784839644532631\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.204973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6784839644532631, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6784839644532631\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=177, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=177\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7395551215892824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7395551215892824\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=177, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7395551215892824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7395551215892824\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.207926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=177, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7395551215892824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7395551215892824\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861746909439679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5861746909439679\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861746909439679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5861746909439679\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.240363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861746909439679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5861746909439679\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5273430107657299, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5273430107657299\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5273430107657299, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5273430107657299\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.206766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5273430107657299, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5273430107657299\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8307158906254093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8307158906254093\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8307158906254093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8307158906254093\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.240494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6784839644532631, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6784839644532631\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6784839644532631, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6784839644532631\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=177, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=177\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7395551215892824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7395551215892824\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=177, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7395551215892824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7395551215892824\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.202093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=177, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7395551215892824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7395551215892824\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861746909439679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5861746909439679\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861746909439679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5861746909439679\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.212394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861746909439679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5861746909439679\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5273430107657299, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5273430107657299\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5273430107657299, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5273430107657299\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5273430107657299, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5273430107657299\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8307158906254093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8307158906254093\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8307158906254093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8307158906254093\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8307158906254093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8307158906254093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:18:41,812] Trial 48 finished with value: 0.6223446610581136 and parameters: {'learning_rate': 0.003777958208245465, 'min_data_in_leaf': 147, 'num_leaves': 7, 'max_depth': 3, 'bagging_fraction': 0.8307158906254093, 'bagging_freq': 11, 'reg_lambda': 0.008944737395612702, 'reg_alpha': 0.0025305024377657447}. Best is trial 18 with value: 0.8233153574808778.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:19:26,386] Trial 49 finished with value: 0.8236954424252 and parameters: {'learning_rate': 0.20894242777133437, 'min_data_in_leaf': 356, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.7850825614230649, 'bagging_freq': 14, 'reg_lambda': 0.395950478953207, 'reg_alpha': 3.5005377967326226}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:20:45,920] Trial 50 finished with value: 0.8208022832442421 and parameters: {'learning_rate': 0.6064890789967529, 'min_data_in_leaf': 405, 'num_leaves': 4, 'max_depth': 2, 'bagging_fraction': 0.7780941826928041, 'bagging_freq': 16, 'reg_lambda': 21.410207702688833, 'reg_alpha': 3.1636107609112663}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=254, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229868825435052, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229868825435052\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.162110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=254, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229868825435052, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229868825435052\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=361, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=361\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6406089351880103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6406089351880103\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=361, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=361\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6406089351880103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6406089351880103\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.230739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=361, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=361\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6406089351880103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6406089351880103\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=570, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=570\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5566403547984045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5566403547984045\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=570, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=570\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5566403547984045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5566403547984045\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.213183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=570, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=570\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5566403547984045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5566403547984045\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7386015279171004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7386015279171004\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7386015279171004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7386015279171004\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7386015279171004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7386015279171004\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=354, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=354\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7923257810927695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923257810927695\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=354, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=354\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7923257810927695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923257810927695\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=354, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=354\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7923257810927695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923257810927695\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=254, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229868825435052, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229868825435052\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=254, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229868825435052, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229868825435052\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=361, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=361\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6406089351880103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6406089351880103\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=361, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=361\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6406089351880103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6406089351880103\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.204083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=361, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=361\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6406089351880103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6406089351880103\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=570, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=570\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5566403547984045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5566403547984045\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=570, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=570\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5566403547984045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5566403547984045\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.237342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=570, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=570\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5566403547984045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5566403547984045\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7386015279171004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7386015279171004\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7386015279171004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7386015279171004\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.244835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7386015279171004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7386015279171004\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=354, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=354\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7923257810927695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923257810927695\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=354, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=354\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7923257810927695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923257810927695\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=354, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=354\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=254, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229868825435052, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229868825435052\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.206459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=254, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229868825435052, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229868825435052\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=361, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=361\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6406089351880103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6406089351880103\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=361, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=361\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6406089351880103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6406089351880103\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.204590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=361, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=361\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6406089351880103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6406089351880103\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=570, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=570\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5566403547984045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5566403547984045\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=570, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=570\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5566403547984045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5566403547984045\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.229754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=570, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=570\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5566403547984045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5566403547984045\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7386015279171004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7386015279171004\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7386015279171004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7386015279171004\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.186569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7386015279171004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7386015279171004\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=354, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=354\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7923257810927695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923257810927695\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=354, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=354\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7923257810927695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923257810927695\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.244222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=354, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=354\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7923257810927695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923257810927695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:21:30,998] Trial 51 finished with value: 0.8233299739879344 and parameters: {'learning_rate': 0.17693197710624461, 'min_data_in_leaf': 354, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.7923257810927695, 'bagging_freq': 14, 'reg_lambda': 0.1558797603316247, 'reg_alpha': 3.249222004712233}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.216717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6784839644532631, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6784839644532631\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=177, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=177\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7395551215892824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7395551215892824\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=177, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7395551215892824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7395551215892824\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=177, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7395551215892824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7395551215892824\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861746909439679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5861746909439679\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861746909439679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5861746909439679\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.235809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861746909439679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5861746909439679\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5273430107657299, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5273430107657299\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5273430107657299, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5273430107657299\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=215, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5273430107657299, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5273430107657299\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8307158906254093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8307158906254093\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8307158906254093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8307158906254093\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.216661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8307158906254093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8307158906254093\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=357, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:22:15,694] Trial 52 finished with value: 0.8225424641385051 and parameters: {'learning_rate': 0.09490604280859058, 'min_data_in_leaf': 357, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.7901309826110019, 'bagging_freq': 14, 'reg_lambda': 0.35817173602322583, 'reg_alpha': 0.7148396672995}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=512, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=512\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7680155261629938, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7680155261629938\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=512, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=512\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7680155261629938, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7680155261629938\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=412, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=412\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769947539013572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769947539013572\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=412, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=412\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769947539013572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769947539013572\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.138882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=412, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=412\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769947539013572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769947539013572\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=473, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=473\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7840602729336841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7840602729336841\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=473, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=473\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7840602729336841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7840602729336841\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=473, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=473\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7840602729336841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7840602729336841\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.188590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8250746918136351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8250746918136351\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8250746918136351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8250746918136351\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.186573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=512, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=512\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7680155261629938, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7680155261629938\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.218697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=512, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=512\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7680155261629938, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7680155261629938\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=412, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=412\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769947539013572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769947539013572\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=412, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=412\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769947539013572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769947539013572\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.264566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=412, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=412\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769947539013572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769947539013572\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=473, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=473\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7840602729336841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7840602729336841\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=473, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=473\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7840602729336841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7840602729336841\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=473, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=473\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7840602729336841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7840602729336841\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.239952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8250746918136351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8250746918136351\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8250746918136351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8250746918136351\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.195439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8250746918136351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8250746918136351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=512, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=512\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7680155261629938, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7680155261629938\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.199375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=512, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=512\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7680155261629938, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7680155261629938\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=412, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=412\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769947539013572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769947539013572\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=412, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=412\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769947539013572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769947539013572\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.202885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=412, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=412\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769947539013572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769947539013572\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=473, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=473\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7840602729336841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7840602729336841\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=473, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=473\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7840602729336841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7840602729336841\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.193437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=473, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=473\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7840602729336841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7840602729336841\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.216863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8250746918136351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8250746918136351\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8250746918136351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8250746918136351\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8250746918136351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8250746918136351\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=512, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=512\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7680155261629938, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7680155261629938\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.211530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=512, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=512\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7680155261629938, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7680155261629938\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=412, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=412\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769947539013572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769947539013572\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=412, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=412\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769947539013572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769947539013572\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=412, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=412\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769947539013572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769947539013572\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=473, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=473\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7840602729336841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7840602729336841\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=473, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=473\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7840602729336841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7840602729336841\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=473, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=473\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7840602729336841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7840602729336841\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.166512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8250746918136351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8250746918136351\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8250746918136351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8250746918136351\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.185594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=471, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8250746918136351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8250746918136351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:23:00,408] Trial 53 finished with value: 0.8226097713070153 and parameters: {'learning_rate': 0.1337449326627688, 'min_data_in_leaf': 471, 'num_leaves': 4, 'max_depth': 1, 'bagging_fraction': 0.8250746918136351, 'bagging_freq': 16, 'reg_lambda': 2.2440990044789872, 'reg_alpha': 3.6264980744779063}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:23:45,619] Trial 54 finished with value: 0.8225576820197155 and parameters: {'learning_rate': 0.1823911210742594, 'min_data_in_leaf': 343, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.8599028210888153, 'bagging_freq': 15, 'reg_lambda': 0.16982339102318345, 'reg_alpha': 24.067304230062035}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:24:31,123] Trial 55 finished with value: 0.8229559536550912 and parameters: {'learning_rate': 0.06500884237900892, 'min_data_in_leaf': 532, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.7623361075645437, 'bagging_freq': 14, 'reg_lambda': 0.04334501734531665, 'reg_alpha': 5.173251946794321}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:25:16,208] Trial 56 finished with value: 0.820614261179691 and parameters: {'learning_rate': 0.3369911709217583, 'min_data_in_leaf': 444, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.7949006547649113, 'bagging_freq': 13, 'reg_lambda': 0.6460362496445995, 'reg_alpha': 22.64826634081406}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:26:00,860] Trial 57 finished with value: 0.822676644559861 and parameters: {'learning_rate': 0.03932888273161093, 'min_data_in_leaf': 384, 'num_leaves': 4, 'max_depth': 1, 'bagging_fraction': 0.7025545236839973, 'bagging_freq': 19, 'reg_lambda': 0.004702999212063359, 'reg_alpha': 1.9229219022211492}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:26:45,927] Trial 58 finished with value: 0.8228472550929407 and parameters: {'learning_rate': 0.2370568619525001, 'min_data_in_leaf': 242, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.8290138597385214, 'bagging_freq': 12, 'reg_lambda': 0.011573927875031195, 'reg_alpha': 0.9215858978816529}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:27:30,423] Trial 59 finished with value: 0.8215341365432063 and parameters: {'learning_rate': 0.48350432540489074, 'min_data_in_leaf': 287, 'num_leaves': 5, 'max_depth': 1, 'bagging_fraction': 0.7554079632986042, 'bagging_freq': 15, 'reg_lambda': 0.027047509720902817, 'reg_alpha': 0.10255131603189287}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:29:30,349] Trial 60 finished with value: 0.8209377586784938 and parameters: {'learning_rate': 0.9709129677433648, 'min_data_in_leaf': 752, 'num_leaves': 6, 'max_depth': 3, 'bagging_fraction': 0.5769216143484992, 'bagging_freq': 13, 'reg_lambda': 0.06285600516913133, 'reg_alpha': 11.524410262489733}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:30:15,529] Trial 61 finished with value: 0.8232515074265482 and parameters: {'learning_rate': 0.20069679693165915, 'min_data_in_leaf': 205, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7254509054551278, 'bagging_freq': 11, 'reg_lambda': 0.11983930265277536, 'reg_alpha': 0.00013309630014670697}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=319, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6591980415344468, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6591980415344468\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.251047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=319, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6591980415344468, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6591980415344468\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=405, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=405\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7780941826928041, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7780941826928041\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=405, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=405\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7780941826928041, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7780941826928041\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=405, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=405\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7780941826928041, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7780941826928041\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=343, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=343\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8599028210888153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8599028210888153\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=343, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8599028210888153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8599028210888153\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.202518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=343, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8599028210888153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8599028210888153\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=242, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=242\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8290138597385214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290138597385214\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=242, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8290138597385214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290138597385214\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=242, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8290138597385214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290138597385214\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883564175919417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883564175919417\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883564175919417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883564175919417\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=319, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6591980415344468, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6591980415344468\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.167841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=319, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6591980415344468, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6591980415344468\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=405, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=405\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7780941826928041, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7780941826928041\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=405, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=405\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7780941826928041, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7780941826928041\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=405, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=405\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7780941826928041, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7780941826928041\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=343, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=343\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8599028210888153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8599028210888153\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=343, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8599028210888153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8599028210888153\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.177109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=343, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8599028210888153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8599028210888153\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=242, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=242\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8290138597385214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290138597385214\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=242, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8290138597385214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290138597385214\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.190754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=242, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8290138597385214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290138597385214\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883564175919417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883564175919417\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883564175919417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883564175919417\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883564175919417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883564175919417\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=319, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6591980415344468, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6591980415344468\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.185225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=319, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6591980415344468, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6591980415344468\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=405, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=405\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7780941826928041, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7780941826928041\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=405, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=405\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7780941826928041, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7780941826928041\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.216812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=405, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=405\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7780941826928041, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7780941826928041\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=343, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=343\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8599028210888153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8599028210888153\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=343, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8599028210888153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8599028210888153\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.199556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=343, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8599028210888153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8599028210888153\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=242, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=242\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8290138597385214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290138597385214\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=242, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8290138597385214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290138597385214\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.198498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=242, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8290138597385214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290138597385214\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883564175919417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883564175919417\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883564175919417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883564175919417\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.230055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883564175919417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883564175919417\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=319, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6591980415344468, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6591980415344468\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.237729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=319, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6591980415344468, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6591980415344468\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=405, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=405\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7780941826928041, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7780941826928041\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=405, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=405\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7780941826928041, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7780941826928041\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=405, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=405\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7780941826928041, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7780941826928041\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=343, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=343\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8599028210888153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8599028210888153\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=343, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8599028210888153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8599028210888153\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.234104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=343, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8599028210888153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8599028210888153\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=242, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=242\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8290138597385214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290138597385214\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=242, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8290138597385214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290138597385214\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.247408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=242, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8290138597385214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290138597385214\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883564175919417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883564175919417\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883564175919417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883564175919417\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.150425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=306, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:31:01,325] Trial 62 finished with value: 0.8233530403683207 and parameters: {'learning_rate': 0.19438296402496355, 'min_data_in_leaf': 306, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6883564175919417, 'bagging_freq': 10, 'reg_lambda': 0.1357917716876637, 'reg_alpha': 4.90405438053913}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=570, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=570\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5566403547984045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5566403547984045\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7386015279171004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7386015279171004\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7386015279171004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7386015279171004\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.209142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7386015279171004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7386015279171004\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=354, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=354\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7923257810927695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923257810927695\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=354, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=354\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7923257810927695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923257810927695\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=354, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=354\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7923257810927695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923257810927695\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=532, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=532\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7623361075645437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7623361075645437\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=532, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7623361075645437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7623361075645437\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=532, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7623361075645437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7623361075645437\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7554079632986042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554079632986042\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7554079632986042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554079632986042\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.152734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7554079632986042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554079632986042\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=302, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=302\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883868179860697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883868179860697\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:31:46,799] Trial 63 finished with value: 0.8233410314534554 and parameters: {'learning_rate': 0.1814664392992942, 'min_data_in_leaf': 302, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6883868179860697, 'bagging_freq': 9, 'reg_lambda': 0.2690932429198179, 'reg_alpha': 45.948735828340176}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:32:32,998] Trial 64 finished with value: 0.8230037771574514 and parameters: {'learning_rate': 0.19341752087766295, 'min_data_in_leaf': 227, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6911748027593545, 'bagging_freq': 8, 'reg_lambda': 0.3275249516299513, 'reg_alpha': 27.70502908346383}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:33:18,517] Trial 65 finished with value: 0.8225513115896861 and parameters: {'learning_rate': 0.2724126677333245, 'min_data_in_leaf': 121, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6485629496342662, 'bagging_freq': 9, 'reg_lambda': 0.12861298174790226, 'reg_alpha': 58.8404787499277}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:34:04,487] Trial 66 finished with value: 0.822458849051633 and parameters: {'learning_rate': 0.13522439901115946, 'min_data_in_leaf': 308, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6641981643162517, 'bagging_freq': 8, 'reg_lambda': 0.25699911096266537, 'reg_alpha': 52.36801938285702}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:34:49,782] Trial 67 finished with value: 0.8214111903313337 and parameters: {'learning_rate': 0.45713328964788336, 'min_data_in_leaf': 267, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.699140679424366, 'bagging_freq': 10, 'reg_lambda': 0.5560250302983185, 'reg_alpha': 14.19085130225008}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8307158906254093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8307158906254093\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=357, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=357\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901309826110019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901309826110019\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=357, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=357\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901309826110019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901309826110019\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.206497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=357, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=357\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901309826110019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901309826110019\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=444, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=444\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7949006547649113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949006547649113\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=444, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=444\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7949006547649113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949006547649113\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.200711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=444, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=444\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7949006547649113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949006547649113\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=752, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=752\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769216143484992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769216143484992\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=752, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=752\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769216143484992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769216143484992\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.175784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=752, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=752\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769216143484992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769216143484992\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=227, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=227\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6911748027593545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6911748027593545\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=227, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=227\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6911748027593545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6911748027593545\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=227, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=227\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6911748027593545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6911748027593545\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7192327091002594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7192327091002594\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8307158906254093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8307158906254093\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=357, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=357\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901309826110019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901309826110019\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=357, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=357\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901309826110019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901309826110019\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.236212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=357, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=357\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901309826110019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901309826110019\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=444, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=444\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7949006547649113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949006547649113\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=444, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=444\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7949006547649113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949006547649113\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=444, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=444\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7949006547649113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949006547649113\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=752, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=752\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769216143484992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769216143484992\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=752, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=752\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769216143484992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769216143484992\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.198904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=752, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=752\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769216143484992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769216143484992\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=227, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=227\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6911748027593545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6911748027593545\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=227, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=227\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6911748027593545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6911748027593545\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.190633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=227, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=227\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6911748027593545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6911748027593545\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7192327091002594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7192327091002594\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=357, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=357\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901309826110019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901309826110019\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=357, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=357\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901309826110019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901309826110019\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=357, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=357\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901309826110019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901309826110019\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=444, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=444\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7949006547649113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949006547649113\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=444, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=444\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7949006547649113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949006547649113\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.210132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=444, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=444\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7949006547649113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949006547649113\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=752, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=752\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769216143484992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769216143484992\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=752, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=752\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769216143484992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769216143484992\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=752, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=752\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769216143484992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769216143484992\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=227, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=227\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6911748027593545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6911748027593545\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=227, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=227\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6911748027593545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6911748027593545\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.186518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=227, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=227\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6911748027593545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6911748027593545\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7192327091002594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7192327091002594\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7192327091002594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7192327091002594\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901309826110019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901309826110019\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=357, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=357\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901309826110019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901309826110019\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.189859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=357, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=357\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901309826110019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901309826110019\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=444, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=444\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7949006547649113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949006547649113\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=444, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=444\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7949006547649113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949006547649113\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.218214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=444, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=444\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7949006547649113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949006547649113\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=752, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=752\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769216143484992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769216143484992\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=752, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=752\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769216143484992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769216143484992\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.176515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=752, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=752\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5769216143484992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5769216143484992\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=227, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=227\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6911748027593545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6911748027593545\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=227, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=227\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6911748027593545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6911748027593545\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=227, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=227\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6911748027593545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6911748027593545\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7192327091002594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7192327091002594\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7192327091002594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7192327091002594\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.245251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:35:35,524] Trial 68 finished with value: 0.8208193777352194 and parameters: {'learning_rate': 0.3267574616989645, 'min_data_in_leaf': 198, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7192327091002594, 'bagging_freq': 9, 'reg_lambda': 0.994398131494074, 'reg_alpha': 4.9795066809826}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:36:20,872] Trial 69 finished with value: 0.8235540313505266 and parameters: {'learning_rate': 0.22253500875602977, 'min_data_in_leaf': 335, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7504031770778358, 'bagging_freq': 12, 'reg_lambda': 0.15761348333203537, 'reg_alpha': 0.6095332790107851}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:37:06,553] Trial 70 finished with value: 0.8222058808367915 and parameters: {'learning_rate': 0.1627846133065992, 'min_data_in_leaf': 299, 'num_leaves': 8, 'max_depth': 1, 'bagging_fraction': 0.8150969919126709, 'bagging_freq': 11, 'reg_lambda': 0.15848182353246543, 'reg_alpha': 0.5791514523103336}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7923257810927695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923257810927695\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=532, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=532\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7623361075645437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7623361075645437\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=532, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7623361075645437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7623361075645437\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.200135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=532, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7623361075645437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7623361075645437\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7554079632986042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554079632986042\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7554079632986042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554079632986042\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7554079632986042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554079632986042\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=302, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=302\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883868179860697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883868179860697\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=302, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883868179860697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883868179860697\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.199728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=302, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883868179860697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883868179860697\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=267, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=267\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.699140679424366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.699140679424366\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=267, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.699140679424366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.699140679424366\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.215392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=267, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.699140679424366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.699140679424366\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=337, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=337\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7508200855775986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7508200855775986\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=337, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7508200855775986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7508200855775986\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=532, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=532\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7623361075645437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7623361075645437\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=532, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7623361075645437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7623361075645437\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=532, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7623361075645437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7623361075645437\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7554079632986042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554079632986042\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7554079632986042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554079632986042\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.229328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7554079632986042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554079632986042\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=302, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=302\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883868179860697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883868179860697\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=302, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883868179860697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883868179860697\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=302, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883868179860697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883868179860697\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=267, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=267\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.699140679424366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.699140679424366\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=267, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.699140679424366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.699140679424366\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.198481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=267, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.699140679424366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.699140679424366\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=337, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=337\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7508200855775986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7508200855775986\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=337, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7508200855775986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7508200855775986\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=532, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=532\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7623361075645437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7623361075645437\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=532, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7623361075645437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7623361075645437\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.148261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=532, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7623361075645437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7623361075645437\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7554079632986042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554079632986042\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7554079632986042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554079632986042\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7554079632986042, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554079632986042\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=302, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=302\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883868179860697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883868179860697\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=302, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883868179860697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883868179860697\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.212639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=302, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883868179860697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883868179860697\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=267, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=267\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.699140679424366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.699140679424366\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=267, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.699140679424366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.699140679424366\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.188716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=267, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.699140679424366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.699140679424366\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=337, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=337\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7508200855775986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7508200855775986\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=337, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7508200855775986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7508200855775986\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:37:52,289] Trial 71 finished with value: 0.8233167322734919 and parameters: {'learning_rate': 0.22461986159761863, 'min_data_in_leaf': 337, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7508200855775986, 'bagging_freq': 12, 'reg_lambda': 0.08973565528984362, 'reg_alpha': 1.2746316394058104}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:38:37,777] Trial 72 finished with value: 0.8231254759732558 and parameters: {'learning_rate': 0.2082851652689028, 'min_data_in_leaf': 364, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7489631145498762, 'bagging_freq': 10, 'reg_lambda': 0.24194822231021307, 'reg_alpha': 2.7049262767898274}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8250746918136351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8250746918136351\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7025545236839973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7025545236839973\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7025545236839973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7025545236839973\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.230676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7025545236839973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7025545236839973\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=205, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=205\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7254509054551278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254509054551278\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=205, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7254509054551278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254509054551278\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.202994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=205, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7254509054551278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254509054551278\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6485629496342662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485629496342662\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6485629496342662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485629496342662\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.184043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6485629496342662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485629496342662\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7504031770778358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7504031770778358\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7504031770778358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7504031770778358\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7504031770778358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7504031770778358\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7727295697377621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7727295697377621\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7727295697377621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7727295697377621\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7025545236839973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7025545236839973\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7025545236839973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7025545236839973\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.198753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7025545236839973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7025545236839973\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=205, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=205\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7254509054551278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254509054551278\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=205, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7254509054551278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254509054551278\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.249250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=205, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7254509054551278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254509054551278\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6485629496342662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485629496342662\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6485629496342662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485629496342662\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.231502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6485629496342662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485629496342662\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7504031770778358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7504031770778358\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7504031770778358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7504031770778358\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.193792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7504031770778358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7504031770778358\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7727295697377621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7727295697377621\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7727295697377621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7727295697377621\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7025545236839973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7025545236839973\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7025545236839973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7025545236839973\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.171373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7025545236839973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7025545236839973\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=205, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=205\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7254509054551278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254509054551278\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=205, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7254509054551278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254509054551278\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.206582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=205, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7254509054551278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254509054551278\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6485629496342662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485629496342662\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6485629496342662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485629496342662\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.199218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6485629496342662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485629496342662\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7504031770778358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7504031770778358\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7504031770778358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7504031770778358\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.209656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7504031770778358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7504031770778358\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7727295697377621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7727295697377621\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7727295697377621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7727295697377621\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7025545236839973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7025545236839973\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7025545236839973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7025545236839973\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7025545236839973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7025545236839973\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=205, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=205\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7254509054551278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254509054551278\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=205, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7254509054551278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254509054551278\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.204588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=205, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7254509054551278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7254509054551278\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6485629496342662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485629496342662\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6485629496342662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485629496342662\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.216187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6485629496342662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485629496342662\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7504031770778358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7504031770778358\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7504031770778358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7504031770778358\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7504031770778358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7504031770778358\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7727295697377621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7727295697377621\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7727295697377621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7727295697377621\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:39:23,215] Trial 73 finished with value: 0.8206257485868723 and parameters: {'learning_rate': 0.36442442530346036, 'min_data_in_leaf': 335, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7727295697377621, 'bagging_freq': 12, 'reg_lambda': 0.03194806962224456, 'reg_alpha': 1.455585305407856}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:40:09,176] Trial 74 finished with value: 0.8220428620449236 and parameters: {'learning_rate': 0.14647358895239473, 'min_data_in_leaf': 238, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7268657274050232, 'bagging_freq': 11, 'reg_lambda': 0.09142832754562291, 'reg_alpha': 5.813268776089015}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:40:56,154] Trial 75 finished with value: 0.8228370884959881 and parameters: {'learning_rate': 0.23107760929423868, 'min_data_in_leaf': 331, 'num_leaves': 2, 'max_depth': 2, 'bagging_fraction': 0.7536755098279532, 'bagging_freq': 10, 'reg_lambda': 0.3901376545634094, 'reg_alpha': 1.214112625077316}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:41:43,094] Trial 76 finished with value: 0.8228821914186799 and parameters: {'learning_rate': 0.07370804540580744, 'min_data_in_leaf': 195, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.8054454505859822, 'bagging_freq': 9, 'reg_lambda': 0.12989914438530778, 'reg_alpha': 2.412459394274395}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:42:29,286] Trial 77 finished with value: 0.822747186939233 and parameters: {'learning_rate': 0.09631010841451638, 'min_data_in_leaf': 303, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.872437390534916, 'bagging_freq': 13, 'reg_lambda': 0.017778071249229994, 'reg_alpha': 0.2521557047792713}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:43:16,221] Trial 78 finished with value: 0.8232586871231163 and parameters: {'learning_rate': 0.11839481623674485, 'min_data_in_leaf': 384, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7101744478995082, 'bagging_freq': 11, 'reg_lambda': 0.04453976178141823, 'reg_alpha': 6.631310041949892}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=302, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883868179860697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883868179860697\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.193738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=302, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=302\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883868179860697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883868179860697\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=267, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=267\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.699140679424366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.699140679424366\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=267, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.699140679424366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.699140679424366\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.195077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=267, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.699140679424366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.699140679424366\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=337, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=337\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7508200855775986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7508200855775986\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=337, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7508200855775986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7508200855775986\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.238221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=337, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7508200855775986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7508200855775986\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=331, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=331\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7536755098279532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7536755098279532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=331, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=331\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7536755098279532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7536755098279532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.202247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=331, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=331\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7536755098279532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7536755098279532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=381, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=381\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419628330470492, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419628330470492\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=381, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=381\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419628330470492, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419628330470492\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.245989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=381, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=381\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419628330470492, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419628330470492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:44:02,426] Trial 79 finished with value: 0.0 and parameters: {'learning_rate': 0.0012270180467298566, 'min_data_in_leaf': 381, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.8419628330470492, 'bagging_freq': 12, 'reg_lambda': 0.04060562958417717, 'reg_alpha': 7.865956988710202}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:44:49,849] Trial 80 finished with value: 0.823094082364433 and parameters: {'learning_rate': 0.12168700583346162, 'min_data_in_leaf': 355, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7076719905341053, 'bagging_freq': 7, 'reg_lambda': 0.06427053401460595, 'reg_alpha': 16.240775928197642}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:45:36,276] Trial 81 finished with value: 0.8229869993234599 and parameters: {'learning_rate': 0.1773702775952103, 'min_data_in_leaf': 453, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6329200876444315, 'bagging_freq': 11, 'reg_lambda': 0.4951753570346118, 'reg_alpha': 4.025816362875975}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6883564175919417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883564175919417\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=308, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=308\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6641981643162517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6641981643162517\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=308, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=308\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6641981643162517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6641981643162517\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=308, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=308\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6641981643162517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6641981643162517\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=299, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=299\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150969919126709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150969919126709\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=299, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150969919126709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150969919126709\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.215506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=299, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150969919126709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150969919126709\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=238, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=238\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7268657274050232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7268657274050232\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=238, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7268657274050232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7268657274050232\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.210231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=238, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7268657274050232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7268657274050232\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7101744478995082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101744478995082\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7101744478995082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101744478995082\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7101744478995082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101744478995082\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=398\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7417174787982438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7417174787982438\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7417174787982438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7417174787982438\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6883564175919417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6883564175919417\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=308, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=308\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6641981643162517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6641981643162517\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=308, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=308\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6641981643162517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6641981643162517\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.243187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=308, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=308\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6641981643162517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6641981643162517\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=299, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=299\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150969919126709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150969919126709\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=299, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150969919126709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150969919126709\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=299, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150969919126709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150969919126709\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=238, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=238\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7268657274050232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7268657274050232\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=238, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7268657274050232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7268657274050232\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.148217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=238, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7268657274050232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7268657274050232\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7101744478995082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101744478995082\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7101744478995082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101744478995082\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.160084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7101744478995082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101744478995082\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=398\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7417174787982438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7417174787982438\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7417174787982438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7417174787982438\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=308, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=308\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6641981643162517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6641981643162517\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=308, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=308\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6641981643162517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6641981643162517\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.204357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=308, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=308\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6641981643162517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6641981643162517\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=299, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=299\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150969919126709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150969919126709\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=299, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150969919126709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150969919126709\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=299, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150969919126709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150969919126709\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=238, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=238\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7268657274050232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7268657274050232\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=238, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7268657274050232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7268657274050232\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.215869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=238, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7268657274050232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7268657274050232\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7101744478995082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101744478995082\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7101744478995082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101744478995082\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7101744478995082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101744478995082\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=398\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7417174787982438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7417174787982438\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7417174787982438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7417174787982438\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=308, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=308\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6641981643162517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6641981643162517\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=308, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=308\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6641981643162517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6641981643162517\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.198685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=308, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=308\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6641981643162517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6641981643162517\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=299, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=299\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150969919126709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150969919126709\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=299, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150969919126709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150969919126709\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.206410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=299, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8150969919126709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8150969919126709\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=238, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=238\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7268657274050232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7268657274050232\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=238, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7268657274050232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7268657274050232\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.230866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=238, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=238\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7268657274050232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7268657274050232\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7101744478995082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101744478995082\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7101744478995082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101744478995082\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.239523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=384, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7101744478995082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101744478995082\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=398\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7417174787982438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7417174787982438\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7417174787982438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7417174787982438\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:46:21,191] Trial 82 finished with value: 0.8213137329121296 and parameters: {'learning_rate': 0.28137692493191263, 'min_data_in_leaf': 398, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7417174787982438, 'bagging_freq': 11, 'reg_lambda': 0.8802812414507059, 'reg_alpha': 1.9097174766700786}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:47:06,499] Trial 83 finished with value: 0.8230343020413587 and parameters: {'learning_rate': 0.08636436948634675, 'min_data_in_leaf': 323, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6664556102257825, 'bagging_freq': 8, 'reg_lambda': 0.21587733310967713, 'reg_alpha': 9.607340888594269}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7192327091002594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7192327091002594\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7192327091002594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7192327091002594\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=364, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=364\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7489631145498762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7489631145498762\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=364, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=364\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7489631145498762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7489631145498762\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.216549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=364, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=364\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7489631145498762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7489631145498762\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=195, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=195\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8054454505859822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8054454505859822\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=195, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8054454505859822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8054454505859822\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.207348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=195, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8054454505859822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8054454505859822\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=355, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=355\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7076719905341053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7076719905341053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=355, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=355\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7076719905341053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7076719905341053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.196115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=355, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=355\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7076719905341053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7076719905341053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=276, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=276\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918657580914174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918657580914174\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=276, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918657580914174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918657580914174\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=276, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918657580914174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918657580914174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:47:51,098] Trial 84 finished with value: 0.8231292523538544 and parameters: {'learning_rate': 0.21431944318739493, 'min_data_in_leaf': 276, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6918657580914174, 'bagging_freq': 10, 'reg_lambda': 0.1080947312726956, 'reg_alpha': 0.851406492485657}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:48:35,612] Trial 85 finished with value: 0.8232346875037035 and parameters: {'learning_rate': 0.11558215844458794, 'min_data_in_leaf': 375, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7226729336252948, 'bagging_freq': 12, 'reg_lambda': 0.020960876887207477, 'reg_alpha': 0.45337408641912497}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:49:20,345] Trial 86 finished with value: 0.821920750887442 and parameters: {'learning_rate': 0.14979421512272412, 'min_data_in_leaf': 249, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.7993047914985703, 'bagging_freq': 12, 'reg_lambda': 0.046469819179267305, 'reg_alpha': 38.25626304177349}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:50:29,552] Trial 87 finished with value: 0.8209434501623254 and parameters: {'learning_rate': 0.390706179340614, 'min_data_in_leaf': 341, 'num_leaves': 3, 'max_depth': 2, 'bagging_fraction': 0.7820509307488986, 'bagging_freq': 10, 'reg_lambda': 1.8615117524006053, 'reg_alpha': 6.806957383701357}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7192327091002594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7192327091002594\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7192327091002594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7192327091002594\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=364, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=364\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7489631145498762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7489631145498762\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=364, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=364\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7489631145498762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7489631145498762\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.210510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=364, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=364\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7489631145498762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7489631145498762\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=195, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=195\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8054454505859822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8054454505859822\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=195, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8054454505859822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8054454505859822\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.283294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=195, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8054454505859822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8054454505859822\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=355, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=355\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7076719905341053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7076719905341053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=355, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=355\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7076719905341053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7076719905341053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.175907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=355, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=355\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7076719905341053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7076719905341053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=276, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=276\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918657580914174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918657580914174\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=276, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918657580914174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918657580914174\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.206881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=276, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918657580914174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918657580914174\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7192327091002594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7192327091002594\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=364, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=364\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7489631145498762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7489631145498762\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=364, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=364\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7489631145498762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7489631145498762\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=364, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=364\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7489631145498762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7489631145498762\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=195, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=195\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8054454505859822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8054454505859822\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=195, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8054454505859822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8054454505859822\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.236799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=195, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8054454505859822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8054454505859822\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=355, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=355\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7076719905341053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7076719905341053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=355, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=355\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7076719905341053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7076719905341053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.244247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=355, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=355\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7076719905341053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7076719905341053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=276, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=276\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918657580914174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918657580914174\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=276, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918657580914174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918657580914174\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.212482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=276, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918657580914174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918657580914174\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=972, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=972\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7681275791469103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7681275791469103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7192327091002594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7192327091002594\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=364, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=364\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7489631145498762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7489631145498762\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=364, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=364\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7489631145498762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7489631145498762\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=364, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=364\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7489631145498762, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7489631145498762\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=195, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=195\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8054454505859822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8054454505859822\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=195, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8054454505859822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8054454505859822\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=195, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8054454505859822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8054454505859822\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=355, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=355\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7076719905341053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7076719905341053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=355, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=355\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7076719905341053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7076719905341053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=355, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=355\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7076719905341053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7076719905341053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=276, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=276\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918657580914174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918657580914174\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=276, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918657580914174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918657580914174\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.202681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=276, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918657580914174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918657580914174\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=972, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=972\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7681275791469103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7681275791469103\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=972, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:51:14,173] Trial 88 finished with value: 0.8229259019917113 and parameters: {'learning_rate': 0.1928739539105207, 'min_data_in_leaf': 972, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7681275791469103, 'bagging_freq': 13, 'reg_lambda': 0.07325545592381072, 'reg_alpha': 17.80167565803809}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:51:59,286] Trial 89 finished with value: 0.8219271938056625 and parameters: {'learning_rate': 0.7309430676866113, 'min_data_in_leaf': 309, 'num_leaves': 7, 'max_depth': 1, 'bagging_fraction': 0.7438917141635047, 'bagging_freq': 11, 'reg_lambda': 0.1673530410466541, 'reg_alpha': 1.4756035039492257}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:52:46,525] Trial 90 finished with value: 0.8215460283415001 and parameters: {'learning_rate': 0.47550402588487506, 'min_data_in_leaf': 909, 'num_leaves': 5, 'max_depth': 1, 'bagging_fraction': 0.731590280481895, 'bagging_freq': 14, 'reg_lambda': 0.2801203430534882, 'reg_alpha': 3.6134156094921677}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.206648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=337, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7508200855775986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7508200855775986\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=331, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=331\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7536755098279532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7536755098279532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=331, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=331\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7536755098279532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7536755098279532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=331, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=331\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7536755098279532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7536755098279532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=381, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=381\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419628330470492, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419628330470492\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=381, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=381\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419628330470492, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419628330470492\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=381, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=381\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419628330470492, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419628330470492\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=323, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=323\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6664556102257825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6664556102257825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=323, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=323\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6664556102257825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6664556102257825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.255005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=323, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=323\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6664556102257825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6664556102257825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=341, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=341\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7820509307488986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7820509307488986\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=341, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=341\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7820509307488986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7820509307488986\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.212822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=341, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=341\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7820509307488986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7820509307488986\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=283, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=283\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.152639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=337, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7508200855775986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7508200855775986\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=331, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=331\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7536755098279532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7536755098279532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=331, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=331\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7536755098279532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7536755098279532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=331, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=331\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7536755098279532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7536755098279532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=381, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=381\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419628330470492, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419628330470492\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=381, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=381\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419628330470492, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419628330470492\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.239656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=381, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=381\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419628330470492, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419628330470492\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=323, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=323\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6664556102257825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6664556102257825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=323, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=323\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6664556102257825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6664556102257825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.167160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=323, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=323\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6664556102257825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6664556102257825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=341, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=341\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7820509307488986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7820509307488986\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=341, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=341\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7820509307488986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7820509307488986\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=341, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=341\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7820509307488986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7820509307488986\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=283, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=283\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.242669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=337, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7508200855775986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7508200855775986\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=331, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=331\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7536755098279532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7536755098279532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=331, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=331\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7536755098279532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7536755098279532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.232834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=331, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=331\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7536755098279532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7536755098279532\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=381, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=381\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419628330470492, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419628330470492\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=381, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=381\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419628330470492, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419628330470492\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=381, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=381\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419628330470492, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419628330470492\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=323, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=323\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6664556102257825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6664556102257825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=323, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=323\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6664556102257825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6664556102257825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=323, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=323\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6664556102257825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6664556102257825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=341, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=341\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7820509307488986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7820509307488986\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=341, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=341\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7820509307488986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7820509307488986\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=341, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=341\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7820509307488986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7820509307488986\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=283, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=283\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6743678538727326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6743678538727326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:53:31,373] Trial 91 finished with value: 0.8225537778668688 and parameters: {'learning_rate': 0.27135767663544424, 'min_data_in_leaf': 283, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6743678538727326, 'bagging_freq': 12, 'reg_lambda': 0.09871427455709118, 'reg_alpha': 2.7244874623114748}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:54:15,937] Trial 92 finished with value: 0.8225968332391549 and parameters: {'learning_rate': 0.25124721047588255, 'min_data_in_leaf': 263, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7130827028161394, 'bagging_freq': 13, 'reg_lambda': 0.00044651646262369444, 'reg_alpha': 0.18870779413169503}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.186489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7727295697377621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7727295697377621\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=303, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=303\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872437390534916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872437390534916\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=303, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872437390534916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872437390534916\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=303, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872437390534916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872437390534916\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=453, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=453\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6329200876444315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329200876444315\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=453, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6329200876444315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329200876444315\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.200741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=453, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6329200876444315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329200876444315\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=375, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=375\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7226729336252948, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7226729336252948\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=375, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7226729336252948, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7226729336252948\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.189680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=375, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7226729336252948, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7226729336252948\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=309, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=309\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7438917141635047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7438917141635047\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=309, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7438917141635047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7438917141635047\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.193626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=309, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7438917141635047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7438917141635047\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=217, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=217\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.252591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7727295697377621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7727295697377621\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=303, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=303\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872437390534916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872437390534916\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=303, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872437390534916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872437390534916\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=303, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872437390534916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872437390534916\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=453, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=453\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6329200876444315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329200876444315\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=453, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6329200876444315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329200876444315\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.240821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=453, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6329200876444315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329200876444315\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=375, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=375\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7226729336252948, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7226729336252948\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=375, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7226729336252948, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7226729336252948\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=375, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7226729336252948, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7226729336252948\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=309, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=309\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7438917141635047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7438917141635047\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=309, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7438917141635047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7438917141635047\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=309, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7438917141635047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7438917141635047\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=217, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=217\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918174568431367, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918174568431367[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.204556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7727295697377621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7727295697377621\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=303, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=303\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872437390534916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872437390534916\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=303, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872437390534916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872437390534916\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.209822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=303, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872437390534916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872437390534916\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=453, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=453\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6329200876444315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329200876444315\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=453, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6329200876444315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329200876444315\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.200528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=453, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6329200876444315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329200876444315\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=375, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=375\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7226729336252948, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7226729336252948\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=375, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7226729336252948, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7226729336252948\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=375, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7226729336252948, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7226729336252948\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=309, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=309\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7438917141635047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7438917141635047\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=309, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7438917141635047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7438917141635047\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.240724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=309, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7438917141635047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7438917141635047\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=217, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=217\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918174568431367, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918174568431367[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.189649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=335, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7727295697377621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7727295697377621\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=303, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=303\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872437390534916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872437390534916\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=303, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872437390534916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872437390534916\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=303, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.872437390534916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872437390534916\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=453, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=453\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6329200876444315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329200876444315\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=453, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6329200876444315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329200876444315\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.228591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=453, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6329200876444315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329200876444315\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=375, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=375\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7226729336252948, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7226729336252948\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=375, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7226729336252948, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7226729336252948\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.240417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=375, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7226729336252948, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7226729336252948\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=309, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=309\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7438917141635047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7438917141635047\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=309, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7438917141635047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7438917141635047\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.200927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=309, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7438917141635047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7438917141635047\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=217, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=217\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:55:01,308] Trial 93 finished with value: 0.8207917090780518 and parameters: {'learning_rate': 0.3170267499598697, 'min_data_in_leaf': 217, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.6918174568431367, 'bagging_freq': 11, 'reg_lambda': 0.1362730582757639, 'reg_alpha': 4.852381881747895}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:55:46,075] Trial 94 finished with value: 0.8217867855658805 and parameters: {'learning_rate': 0.16394424518314993, 'min_data_in_leaf': 352, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.6490197368917101, 'bagging_freq': 12, 'reg_lambda': 0.03615150923767715, 'reg_alpha': 1.1030510299624092}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:56:31,241] Trial 95 finished with value: 0.8233373257291319 and parameters: {'learning_rate': 0.2245012132073722, 'min_data_in_leaf': 231, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.8172180070154448, 'bagging_freq': 15, 'reg_lambda': 0.19838578261610385, 'reg_alpha': 2.0731938148394105}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:57:15,896] Trial 96 finished with value: 0.8232431420694134 and parameters: {'learning_rate': 0.1098907641798264, 'min_data_in_leaf': 151, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7903748778711058, 'bagging_freq': 15, 'reg_lambda': 0.45223535495606837, 'reg_alpha': 1.7612926026849614}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:58:00,594] Trial 97 finished with value: 0.8230934193691314 and parameters: {'learning_rate': 0.13749165582431933, 'min_data_in_leaf': 233, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.8144897031654106, 'bagging_freq': 17, 'reg_lambda': 0.055476905541157216, 'reg_alpha': 0.6928091784171551}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-01-07 12:58:46,724] Trial 98 finished with value: 0.8228118388276559 and parameters: {'learning_rate': 0.05185189977283567, 'min_data_in_leaf': 188, 'num_leaves': 2, 'max_depth': 1, 'bagging_fraction': 0.7589172491250494, 'bagging_freq': 16, 'reg_lambda': 0.16531778479107145, 'reg_alpha': 11.955681028830538}. Best is trial 49 with value: 0.8236954424252.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `max_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=323, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=323\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6664556102257825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6664556102257825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=323, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=323\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6664556102257825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6664556102257825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=323, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=323\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6664556102257825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6664556102257825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=341, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=341\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7820509307488986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7820509307488986\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=341, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=341\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7820509307488986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7820509307488986\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.213504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=341, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=341\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7820509307488986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7820509307488986\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=283, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=283\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6743678538727326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6743678538727326\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=283, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=283\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6743678538727326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6743678538727326\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.212564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=283, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=283\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6743678538727326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6743678538727326\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=231, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=231\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8172180070154448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172180070154448\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=231, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=231\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8172180070154448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172180070154448\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=231, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=231\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8172180070154448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172180070154448\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=293, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=293\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7748388624489543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7748388624489543\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=293, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=293\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7748388624489543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7748388624489543\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 12:59:33,031] Trial 99 finished with value: 0.8232677166428554 and parameters: {'learning_rate': 0.20661484596452048, 'min_data_in_leaf': 293, 'num_leaves': 3, 'max_depth': 1, 'bagging_fraction': 0.7748388624489543, 'bagging_freq': 15, 'reg_lambda': 0.1941024844812741, 'reg_alpha': 6.842635151205169}. Best is trial 49 with value: 0.8236954424252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-07 12:59:33,034: 92: logger: INFO: common:  json file saved at: logs/LGBMClassifier.json]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7850825614230649, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7850825614230649\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 2949246, number of negative: 1337063\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 4286309, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.688062 -> initscore=0.791074\n",
      "[LightGBM] [Info] Start training from score 0.791074\n",
      "[2024-01-07 12:59:35,445: 150: logger: INFO: stacking_model_training:  Model LGBMClassifier has been tuned]\n",
      "[2024-01-07 12:59:35,452: 189: logger: INFO: stacking_model_training:  === FINISHED TRAINING STAGE for stacking models ===]\n",
      "CPU times: user 1min 26s, sys: 14.2 s, total: 1min 40s\n",
      "Wall time: 1h 30min 24s\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7681275791469103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7681275791469103\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.245003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=972, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7681275791469103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7681275791469103\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7130827028161394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7130827028161394\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7130827028161394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7130827028161394\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.228565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7130827028161394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7130827028161394\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=151, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=151\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7903748778711058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7903748778711058\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=151, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=151\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7903748778711058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7903748778711058\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=151, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=151\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7903748778711058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7903748778711058\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=972, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7681275791469103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7681275791469103\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.202270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=972, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7681275791469103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7681275791469103\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7130827028161394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7130827028161394\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7130827028161394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7130827028161394\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7130827028161394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7130827028161394\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=151, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=151\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7903748778711058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7903748778711058\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=151, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=151\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7903748778711058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7903748778711058\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.202219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=151, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=151\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7903748778711058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7903748778711058\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=972, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=972\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7681275791469103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7681275791469103\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=972, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7681275791469103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7681275791469103\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.164405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=972, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7681275791469103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7681275791469103\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7130827028161394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7130827028161394\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7130827028161394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7130827028161394\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.177766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7130827028161394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7130827028161394\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=151, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=151\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7903748778711058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7903748778711058\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=151, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=151\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7903748778711058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7903748778711058\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.230739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=151, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=151\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7903748778711058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7903748778711058\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=972, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=972\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7681275791469103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7681275791469103\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=972, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7681275791469103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7681275791469103\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=972, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7681275791469103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7681275791469103\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7130827028161394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7130827028161394\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7130827028161394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7130827028161394\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.171691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=263, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7130827028161394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7130827028161394\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=151, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=151\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7903748778711058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7903748778711058\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=151, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=151\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7903748778711058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7903748778711058\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.210109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=151, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=151\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7903748778711058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7903748778711058\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=217, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=217\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918174568431367, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918174568431367\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.204136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=217, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=217\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918174568431367, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918174568431367\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=233, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=233\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8144897031654106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144897031654106\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=233, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=233\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8144897031654106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144897031654106\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.204990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=233, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=233\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8144897031654106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144897031654106\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=217, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=217\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918174568431367, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918174568431367\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=217, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=217\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918174568431367, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918174568431367\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=233, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=233\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8144897031654106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144897031654106\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=233, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=233\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8144897031654106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144897031654106\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=233, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=233\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8144897031654106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144897031654106\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918174568431367, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918174568431367\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=217, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=217\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918174568431367, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918174568431367\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.215328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=217, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=217\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918174568431367, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918174568431367\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=233, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=233\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8144897031654106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144897031654106\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=233, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=233\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8144897031654106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144897031654106\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=233, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=233\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8144897031654106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144897031654106\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918174568431367, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918174568431367\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=217, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=217\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918174568431367, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918174568431367\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=217, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=217\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6918174568431367, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6918174568431367\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=233, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=233\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8144897031654106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144897031654106\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=233, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=233\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8144897031654106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144897031654106\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=233, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=233\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8144897031654106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144897031654106\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.233607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7417174787982438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7417174787982438\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=249, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=249\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7993047914985703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7993047914985703\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=249, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=249\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7993047914985703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7993047914985703\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.211779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=249, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=249\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7993047914985703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7993047914985703\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=909, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=909\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731590280481895, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731590280481895\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=909, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=909\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731590280481895, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731590280481895\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.209904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=909, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=909\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731590280481895, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731590280481895\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=352, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=352\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6490197368917101, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490197368917101\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=352, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=352\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6490197368917101, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490197368917101\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.209698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=352, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=352\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6490197368917101, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490197368917101\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7589172491250494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7589172491250494\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7589172491250494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7589172491250494\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.242295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7589172491250494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7589172491250494\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.171063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7417174787982438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7417174787982438\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=249, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=249\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7993047914985703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7993047914985703\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=249, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=249\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7993047914985703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7993047914985703\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.233897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=249, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=249\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7993047914985703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7993047914985703\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=909, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=909\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731590280481895, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731590280481895\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=909, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=909\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731590280481895, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731590280481895\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.170042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=909, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=909\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731590280481895, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731590280481895\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=352, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=352\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6490197368917101, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490197368917101\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=352, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=352\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6490197368917101, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490197368917101\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.196819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=352, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=352\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6490197368917101, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490197368917101\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7589172491250494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7589172491250494\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7589172491250494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7589172491250494\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.198021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7589172491250494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7589172491250494\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7417174787982438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7417174787982438\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=249, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=249\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7993047914985703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7993047914985703\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=249, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=249\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7993047914985703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7993047914985703\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.198619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=249, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=249\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7993047914985703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7993047914985703\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=909, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=909\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731590280481895, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731590280481895\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=909, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=909\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731590280481895, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731590280481895\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.154985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=909, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=909\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731590280481895, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731590280481895\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=352, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=352\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6490197368917101, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490197368917101\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=352, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=352\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6490197368917101, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490197368917101\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.179643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=352, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=352\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6490197368917101, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490197368917101\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7589172491250494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7589172491250494\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7589172491250494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7589172491250494\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7589172491250494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7589172491250494\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7417174787982438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7417174787982438\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=249, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=249\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7993047914985703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7993047914985703\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=249, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=249\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7993047914985703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7993047914985703\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.216373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=249, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=249\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7993047914985703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7993047914985703\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=909, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=909\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731590280481895, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731590280481895\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=909, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=909\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731590280481895, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731590280481895\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.174633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=909, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=909\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731590280481895, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731590280481895\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=352, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=352\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6490197368917101, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490197368917101\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=352, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=352\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6490197368917101, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490197368917101\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=352, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=352\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6490197368917101, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490197368917101\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7589172491250494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7589172491250494\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7589172491250494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7589172491250494\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7589172491250494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7589172491250494\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6743678538727326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6743678538727326\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=283, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=283\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6743678538727326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6743678538727326\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=283, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=283\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6743678538727326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6743678538727326\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=231, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=231\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8172180070154448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172180070154448\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=231, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=231\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8172180070154448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172180070154448\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.216665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=231, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=231\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8172180070154448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172180070154448\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=293, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=293\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7748388624489543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7748388624489543\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=293, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=293\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7748388624489543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7748388624489543\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=293, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=293\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7748388624489543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7748388624489543\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6743678538727326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6743678538727326\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=283, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=283\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6743678538727326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6743678538727326\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.258194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=283, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=283\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6743678538727326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6743678538727326\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=231, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=231\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8172180070154448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172180070154448\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=231, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=231\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8172180070154448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172180070154448\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=231, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=231\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8172180070154448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172180070154448\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=293, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=293\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7748388624489543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7748388624489543\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=293, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=293\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7748388624489543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7748388624489543\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002798, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.248072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791073\n",
      "[LightGBM] [Info] Start training from score -0.791073\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=293, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=293\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7748388624489543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7748388624489543\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=283, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=283\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6743678538727326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6743678538727326\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=283, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=283\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6743678538727326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6743678538727326\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=231, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=231\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8172180070154448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172180070154448\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=231, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=231\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8172180070154448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172180070154448\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211934\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.168660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214731, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791074\n",
      "[LightGBM] [Info] Start training from score -0.791074\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=231, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=231\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8172180070154448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172180070154448\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=293, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=293\n",
      "[LightGBM] [Warning] num_iterations is set=100, max_iter=100 will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7748388624489543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7748388624489543\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=293, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=293\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7748388624489543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7748388624489543\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Number of positive: 1002797, number of negative: 2211935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.198388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=293, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=293\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7748388624489543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7748388624489543\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 3214732, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.311938 -> initscore=-0.791075\n",
      "[LightGBM] [Info] Start training from score -0.791075\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=293, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=293\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7748388624489543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7748388624489543\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "component = StackingModelTraining(stacking_model_training_config, config_manager.config.path,\n",
    "                                  models=['LGBMClassifier'])\n",
    "component.run_stage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d8c1f2-57a3-45ca-9b96-92148ba87cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-07 10:41:55,351: 47: logger: INFO: common:  yaml file: src/params/XGBClassifier.yaml loaded successfully]\n",
      "[2024-01-07 10:41:55,353: 174: logger: INFO: stacking_model_training:  === STARTING TRAINING STAGE for stacking models ===]\n",
      "[2024-01-07 10:41:55,390: 171: logger: INFO: common:  tensor file has been loaded from: data/target]\n",
      "[2024-01-07 10:41:57,635: 178: logger: INFO: stacking_model_training:  Part1. Target data has been loaded]\n",
      "[2024-01-07 10:41:57,750: 183: logger: INFO: stacking_model_training:  Part2. First level logits have been loaded]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7f513a55e349759c6eefd9c7dc9eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tuning Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:41:57,757] A new study created in memory with name: no-name-0bbb8789-421b-4096-8ca0-bdfcceab37d7\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-07 10:42:03,749] Trial 0 finished with value: 0.8212512197366812 and parameters: {'learning_rate': 0.013292918943162165, 'max_depth': 1, 'subsample': 0.5780093202212182, 'reg_lambda': 0.0008629132190071859, 'reg_alpha': 0.00022310108018679258}. Best is trial 0 with value: 0.8212512197366812.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:08] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:08] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:08] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:08] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-07 10:42:09,346] Trial 1 finished with value: 0.8204771273456479 and parameters: {'learning_rate': 0.39676050770529875, 'max_depth': 2, 'subsample': 0.9849549260809971, 'reg_lambda': 9.877700294007917, 'reg_alpha': 0.0018794668241638478}. Best is trial 0 with value: 0.8212512197366812.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:14] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:14] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:14] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:14] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-07 10:42:15,286] Trial 2 finished with value: 0.59517136949625 and parameters: {'learning_rate': 0.0035113563139704067, 'max_depth': 3, 'subsample': 0.7159725093210578, 'reg_lambda': 0.005589524205217926, 'reg_alpha': 0.4689400963537689}. Best is trial 0 with value: 0.8212512197366812.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:42:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-07 10:42:21,273] Trial 3 finished with value: 0.0 and parameters: {'learning_rate': 0.002621087878265439, 'max_depth': 3, 'subsample': 0.8925879806965068, 'reg_lambda': 0.0015777663630582469, 'reg_alpha': 0.12173252504194051}. Best is trial 0 with value: 0.8212512197366812.\n",
      "[I 2024-01-07 10:42:26,309] Trial 4 finished with value: 0.8220339675437282 and parameters: {'learning_rate': 0.05987474910461398, 'max_depth': 2, 'subsample': 0.5325257964926398, 'reg_lambda': 49.35296209402104, 'reg_alpha': 62.20025976819163}. Best is trial 4 with value: 0.8220339675437282.\n",
      "[I 2024-01-07 10:42:31,723] Trial 5 finished with value: 0.8206485171838747 and parameters: {'learning_rate': 0.2661901888489056, 'max_depth': 3, 'subsample': 0.7200762468698007, 'reg_lambda': 0.0005397956855996448, 'reg_alpha': 0.09355380606452186}. Best is trial 4 with value: 0.8220339675437282.\n",
      "[I 2024-01-07 10:42:36,750] Trial 6 finished with value: 0.0 and parameters: {'learning_rate': 0.00126813521690846, 'max_depth': 1, 'subsample': 0.6558555380447055, 'reg_lambda': 0.1319496149042567, 'reg_alpha': 0.1906609163818847}. Best is trial 4 with value: 0.8220339675437282.\n",
      "[I 2024-01-07 10:42:41,841] Trial 7 finished with value: 0.0 and parameters: {'learning_rate': 0.0035856126103453977, 'max_depth': 1, 'subsample': 0.9474136752138245, 'reg_lambda': 0.3867228849117747, 'reg_alpha': 33.981724150105975}. Best is trial 4 with value: 0.8220339675437282.\n",
      "[I 2024-01-07 10:42:46,984] Trial 8 finished with value: 0.0 and parameters: {'learning_rate': 0.0018427970406864537, 'max_depth': 3, 'subsample': 0.6943386448447411, 'reg_lambda': 0.004247116662617146, 'reg_alpha': 9.38480071590954}. Best is trial 4 with value: 0.8220339675437282.\n",
      "[I 2024-01-07 10:42:52,186] Trial 9 finished with value: 0.8121851738962893 and parameters: {'learning_rate': 0.011756010900231853, 'max_depth': 2, 'subsample': 0.9010984903770198, 'reg_lambda': 0.00028009403633756793, 'reg_alpha': 83.4298801304735}. Best is trial 4 with value: 0.8220339675437282.\n",
      "[I 2024-01-07 10:42:57,310] Trial 10 finished with value: 0.8219675753917028 and parameters: {'learning_rate': 0.08237784729054834, 'max_depth': 2, 'subsample': 0.5037736596581465, 'reg_lambda': 53.81074121266518, 'reg_alpha': 2.72901603959624}. Best is trial 4 with value: 0.8220339675437282.\n",
      "[I 2024-01-07 10:43:02,495] Trial 11 finished with value: 0.8219879002920447 and parameters: {'learning_rate': 0.08412264985872193, 'max_depth': 2, 'subsample': 0.5054512650166778, 'reg_lambda': 66.27585200598135, 'reg_alpha': 2.6942213191525552}. Best is trial 4 with value: 0.8220339675437282.\n",
      "[I 2024-01-07 10:43:07,556] Trial 12 finished with value: 0.8218815427335233 and parameters: {'learning_rate': 0.08684882939735407, 'max_depth': 2, 'subsample': 0.5117397233390728, 'reg_lambda': 3.401866813867285, 'reg_alpha': 2.6036604155071124}. Best is trial 4 with value: 0.8220339675437282.\n",
      "[I 2024-01-07 10:43:12,681] Trial 13 finished with value: 0.8220900025024023 and parameters: {'learning_rate': 0.07221074562457087, 'max_depth': 2, 'subsample': 0.5998075613497369, 'reg_lambda': 61.127215081894256, 'reg_alpha': 13.79356146202543}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:43:17,758] Trial 14 finished with value: 0.8209234979034337 and parameters: {'learning_rate': 0.023713837415214475, 'max_depth': 2, 'subsample': 0.6048185530416911, 'reg_lambda': 2.5322276691299384, 'reg_alpha': 0.012184299982788685}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:43:22,904] Trial 15 finished with value: 0.8210241879951294 and parameters: {'learning_rate': 0.8277917979109907, 'max_depth': 2, 'subsample': 0.8028682440454455, 'reg_lambda': 12.077491495127845, 'reg_alpha': 23.89258474425102}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:43:27,983] Trial 16 finished with value: 0.8219968187000293 and parameters: {'learning_rate': 0.043538793381208314, 'max_depth': 2, 'subsample': 0.5837193067328144, 'reg_lambda': 0.9559574710535281, 'reg_alpha': 93.43938714203607}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:43:33,233] Trial 17 finished with value: 0.8215976279269368 and parameters: {'learning_rate': 0.21050682721557434, 'max_depth': 2, 'subsample': 0.6264311929081909, 'reg_lambda': 0.045680785939698466, 'reg_alpha': 10.263733338737708}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:43:38,416] Trial 18 finished with value: 0.8217619046114742 and parameters: {'learning_rate': 0.03368605373115465, 'max_depth': 2, 'subsample': 0.7802142560238521, 'reg_lambda': 92.30307640995305, 'reg_alpha': 0.6926557934237261}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:43:43,475] Trial 19 finished with value: 0.8188077937962838 and parameters: {'learning_rate': 0.008644226145842631, 'max_depth': 1, 'subsample': 0.5559090711183948, 'reg_lambda': 12.814295989370683, 'reg_alpha': 0.012856712986059938}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:43:48,606] Trial 20 finished with value: 0.8216791497361428 and parameters: {'learning_rate': 0.16790056305204482, 'max_depth': 2, 'subsample': 0.6578438913013864, 'reg_lambda': 23.219981191687026, 'reg_alpha': 7.804583950255708}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:43:53,873] Trial 21 finished with value: 0.8220312633793561 and parameters: {'learning_rate': 0.03907754048365226, 'max_depth': 2, 'subsample': 0.565088486136114, 'reg_lambda': 0.9761219049436194, 'reg_alpha': 68.38381419300727}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:43:59,220] Trial 22 finished with value: 0.8220413812482693 and parameters: {'learning_rate': 0.044463816198847574, 'max_depth': 2, 'subsample': 0.5508824035172991, 'reg_lambda': 2.6311226202582265, 'reg_alpha': 33.01840016446619}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:44:04,478] Trial 23 finished with value: 0.8217832287711947 and parameters: {'learning_rate': 0.12194275991562402, 'max_depth': 2, 'subsample': 0.5374116304481703, 'reg_lambda': 4.398670749964694, 'reg_alpha': 20.13724076125878}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:44:09,675] Trial 24 finished with value: 0.8209692945887432 and parameters: {'learning_rate': 0.0236072135594907, 'max_depth': 2, 'subsample': 0.646817641645387, 'reg_lambda': 44.910158037268076, 'reg_alpha': 1.1991683949557859}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:44:15,010] Trial 25 finished with value: 0.8220543107312026 and parameters: {'learning_rate': 0.055465767748535885, 'max_depth': 2, 'subsample': 0.5393673533293736, 'reg_lambda': 0.033745749620315145, 'reg_alpha': 6.447543051024591}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:44:20,165] Trial 26 finished with value: 0.7811847190329118 and parameters: {'learning_rate': 0.007259817556208671, 'max_depth': 2, 'subsample': 0.6063789307887408, 'reg_lambda': 0.02545642575725763, 'reg_alpha': 6.798330459519815}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:44:25,332] Trial 27 finished with value: 0.8186654113558017 and parameters: {'learning_rate': 0.017008314108141107, 'max_depth': 2, 'subsample': 0.816315196381159, 'reg_lambda': 0.1090570265050434, 'reg_alpha': 22.474294910141406}. Best is trial 13 with value: 0.8220900025024023.\n",
      "[I 2024-01-07 10:44:30,420] Trial 28 finished with value: 0.8230485680591209 and parameters: {'learning_rate': 0.05593453687384779, 'max_depth': 1, 'subsample': 0.6866366388462062, 'reg_lambda': 0.2919877974798789, 'reg_alpha': 0.02660801798446914}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:44:35,443] Trial 29 finished with value: 0.8212668005871118 and parameters: {'learning_rate': 0.5134837517177715, 'max_depth': 1, 'subsample': 0.6812469497890212, 'reg_lambda': 0.013376111033886607, 'reg_alpha': 0.00010313040010118277}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:44:40,470] Trial 30 finished with value: 0.8229146072476934 and parameters: {'learning_rate': 0.1569462084472193, 'max_depth': 1, 'subsample': 0.7489194680207966, 'reg_lambda': 0.00010593686631077128, 'reg_alpha': 0.012531523869257091}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:44:45,553] Trial 31 finished with value: 0.8229921565040521 and parameters: {'learning_rate': 0.12806814547803613, 'max_depth': 1, 'subsample': 0.7569356703058007, 'reg_lambda': 0.0001520020158504136, 'reg_alpha': 0.01686896291118511}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:44:50,646] Trial 32 finished with value: 0.8209175069553721 and parameters: {'learning_rate': 0.3544876381204598, 'max_depth': 1, 'subsample': 0.754987126576177, 'reg_lambda': 0.0001448898828096652, 'reg_alpha': 0.013508990890850874}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:44:55,793] Trial 33 finished with value: 0.8222063980616282 and parameters: {'learning_rate': 0.14255481008962495, 'max_depth': 1, 'subsample': 0.7273091283795688, 'reg_lambda': 0.0011467848001899712, 'reg_alpha': 0.004379592190870718}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:45:00,836] Trial 34 finished with value: 0.8221251805846174 and parameters: {'learning_rate': 0.13459143924742084, 'max_depth': 1, 'subsample': 0.8414593390592275, 'reg_lambda': 0.00010595568447806078, 'reg_alpha': 0.001615689726658627}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:45:05,931] Trial 35 finished with value: 0.8223614619808315 and parameters: {'learning_rate': 0.13171133143615327, 'max_depth': 1, 'subsample': 0.7453092942084204, 'reg_lambda': 0.0013297772153590358, 'reg_alpha': 0.003255665296669088}. Best is trial 28 with value: 0.8230485680591209.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:45:10] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-07 10:45:11,026] Trial 36 finished with value: 0.8223491795332939 and parameters: {'learning_rate': 0.264771221496377, 'max_depth': 1, 'subsample': 0.7576326848498705, 'reg_lambda': 0.00042628795871132004, 'reg_alpha': 0.0007790132417148009}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:45:15,872] Trial 37 finished with value: 0.8209665643455997 and parameters: {'learning_rate': 0.35813262609077884, 'max_depth': 1, 'subsample': 0.8500713443272211, 'reg_lambda': 0.0017365038704523527, 'reg_alpha': 0.041871748941268466}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:45:20,997] Trial 38 finished with value: 0.8219947079853083 and parameters: {'learning_rate': 0.7589393015567918, 'max_depth': 1, 'subsample': 0.7254426108920368, 'reg_lambda': 0.00019890820983237446, 'reg_alpha': 0.05495082692152507}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:45:25,981] Trial 39 finished with value: 0.8227734907273219 and parameters: {'learning_rate': 0.11473139871716974, 'max_depth': 1, 'subsample': 0.6972691569490214, 'reg_lambda': 0.0041030164606386055, 'reg_alpha': 0.003971695045915588}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:45:31,049] Trial 40 finished with value: 0.8214954433155397 and parameters: {'learning_rate': 0.5096938242909167, 'max_depth': 1, 'subsample': 0.6917565864249865, 'reg_lambda': 0.00462087131182553, 'reg_alpha': 0.0006753692033854045}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:45:36,160] Trial 41 finished with value: 0.8225465676031742 and parameters: {'learning_rate': 0.10005615033148779, 'max_depth': 1, 'subsample': 0.7806799430693413, 'reg_lambda': 0.0006511403088602632, 'reg_alpha': 0.004092450119919334}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:45:41,173] Trial 42 finished with value: 0.8229628203856544 and parameters: {'learning_rate': 0.10405139611625258, 'max_depth': 1, 'subsample': 0.7921500919005852, 'reg_lambda': 0.0005551651829638638, 'reg_alpha': 0.030661059274075364}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:45:46,592] Trial 43 finished with value: 0.8206143126157687 and parameters: {'learning_rate': 0.20465146465413975, 'max_depth': 3, 'subsample': 0.7107069103162076, 'reg_lambda': 0.0003134563038467657, 'reg_alpha': 0.02644157402724816}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:45:51,612] Trial 44 finished with value: 0.8229209689067958 and parameters: {'learning_rate': 0.06308134414993019, 'max_depth': 1, 'subsample': 0.7814550662989996, 'reg_lambda': 0.24814113483534392, 'reg_alpha': 0.2108640151933459}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:45:56,736] Trial 45 finished with value: 0.8229077454815563 and parameters: {'learning_rate': 0.05076910603418661, 'max_depth': 1, 'subsample': 0.8677808331369976, 'reg_lambda': 0.6217756653053497, 'reg_alpha': 0.22974444696754523}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:46:01,817] Trial 46 finished with value: 0.8228937354825667 and parameters: {'learning_rate': 0.0640306727189922, 'max_depth': 1, 'subsample': 0.7861422626900263, 'reg_lambda': 0.15855509270117257, 'reg_alpha': 0.09854318206983942}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:46:07,258] Trial 47 finished with value: 0.8191146374765242 and parameters: {'learning_rate': 0.02569623724084261, 'max_depth': 3, 'subsample': 0.8203530540914283, 'reg_lambda': 0.23596260165038282, 'reg_alpha': 0.3076771353704498}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:46:12,341] Trial 48 finished with value: 0.8229275919566111 and parameters: {'learning_rate': 0.1947851002304485, 'max_depth': 1, 'subsample': 0.8893602926446941, 'reg_lambda': 0.06410452080385927, 'reg_alpha': 0.022065805557385715}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:46:17,516] Trial 49 finished with value: 0.8229909485697773 and parameters: {'learning_rate': 0.07531749406907616, 'max_depth': 1, 'subsample': 0.9763551405686439, 'reg_lambda': 0.015342108791755214, 'reg_alpha': 0.026466352400107467}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:46:22,613] Trial 50 finished with value: 0.8228781001161296 and parameters: {'learning_rate': 0.21845295208009496, 'max_depth': 1, 'subsample': 0.9760187102776892, 'reg_lambda': 0.017275281989600575, 'reg_alpha': 0.025841485397673808}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:46:27,827] Trial 51 finished with value: 0.8229340874125717 and parameters: {'learning_rate': 0.0727141955769651, 'max_depth': 1, 'subsample': 0.9076578105480149, 'reg_lambda': 0.05945010287760884, 'reg_alpha': 0.052747625664564785}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:46:32,954] Trial 52 finished with value: 0.8227444406812416 and parameters: {'learning_rate': 0.09293534277713182, 'max_depth': 1, 'subsample': 0.9170125602859105, 'reg_lambda': 0.06450444549531759, 'reg_alpha': 0.057243898962931465}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:46:37,961] Trial 53 finished with value: 0.8225318577901851 and parameters: {'learning_rate': 0.02922202485435858, 'max_depth': 1, 'subsample': 0.9976449467018242, 'reg_lambda': 0.00975471235937912, 'reg_alpha': 0.020191580649313562}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:46:42,981] Trial 54 finished with value: 0.8230482733380474 and parameters: {'learning_rate': 0.08005812373092064, 'max_depth': 1, 'subsample': 0.9380268055790324, 'reg_lambda': 0.06621220598137965, 'reg_alpha': 0.006994348019390628}. Best is trial 28 with value: 0.8230485680591209.\n",
      "[I 2024-01-07 10:46:47,945] Trial 55 finished with value: 0.8230878553752775 and parameters: {'learning_rate': 0.07367797781937041, 'max_depth': 1, 'subsample': 0.9650723311157846, 'reg_lambda': 0.007672321785727279, 'reg_alpha': 0.008775699615918831}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:46:53,381] Trial 56 finished with value: 0.8200051820479656 and parameters: {'learning_rate': 0.03557460693460891, 'max_depth': 3, 'subsample': 0.9486230378396795, 'reg_lambda': 0.002236505795094068, 'reg_alpha': 0.00718447061681958}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:46:58,455] Trial 57 finished with value: 0.8226941908510886 and parameters: {'learning_rate': 0.09417220777794671, 'max_depth': 1, 'subsample': 0.9568750278491436, 'reg_lambda': 0.007295404747105419, 'reg_alpha': 0.008296276758650236}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:47:03,556] Trial 58 finished with value: 0.821944003998457 and parameters: {'learning_rate': 0.017876189240065694, 'max_depth': 1, 'subsample': 0.9240306141463763, 'reg_lambda': 0.003031247638164791, 'reg_alpha': 0.1244584723434685}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:47:08,564] Trial 59 finished with value: 0.8229835941814194 and parameters: {'learning_rate': 0.052420762569366466, 'max_depth': 1, 'subsample': 0.9732361665282373, 'reg_lambda': 0.022595317429601986, 'reg_alpha': 0.001148940628623834}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:47:13,552] Trial 60 finished with value: 0.822926372308363 and parameters: {'learning_rate': 0.0505245569309672, 'max_depth': 1, 'subsample': 0.9659566411861628, 'reg_lambda': 0.019126168867949097, 'reg_alpha': 0.001399832903175208}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:47:18,599] Trial 61 finished with value: 0.8228309900542432 and parameters: {'learning_rate': 0.07372536528524011, 'max_depth': 1, 'subsample': 0.9295594248977872, 'reg_lambda': 0.029996054167666205, 'reg_alpha': 0.007828761369701192}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:47:23,611] Trial 62 finished with value: 0.8228134989398805 and parameters: {'learning_rate': 0.04110904546776705, 'max_depth': 1, 'subsample': 0.9892523807602015, 'reg_lambda': 0.0007731037940800354, 'reg_alpha': 0.00046841270676453863}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:47:28,594] Trial 63 finished with value: 0.8229220556624783 and parameters: {'learning_rate': 0.10126271243018674, 'max_depth': 1, 'subsample': 0.9703345754088509, 'reg_lambda': 0.42232555572462654, 'reg_alpha': 0.0023435732707256436}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:47:33,689] Trial 64 finished with value: 0.8228947510717584 and parameters: {'learning_rate': 0.05694308671027518, 'max_depth': 1, 'subsample': 0.9420703686782798, 'reg_lambda': 0.006597237268426411, 'reg_alpha': 0.007279017365282142}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:47:38,781] Trial 65 finished with value: 0.8230529282687569 and parameters: {'learning_rate': 0.08126131880746201, 'max_depth': 1, 'subsample': 0.8732433442270281, 'reg_lambda': 0.011525408099639098, 'reg_alpha': 0.03146986035160977}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:47:44,039] Trial 66 finished with value: 0.8206186278281509 and parameters: {'learning_rate': 0.07684750197708787, 'max_depth': 3, 'subsample': 0.880645544473192, 'reg_lambda': 0.012379654496801928, 'reg_alpha': 0.016206148875716}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:47:49,167] Trial 67 finished with value: 0.8225325166925116 and parameters: {'learning_rate': 0.03169378210781589, 'max_depth': 1, 'subsample': 0.9411639738743449, 'reg_lambda': 0.10499641974756589, 'reg_alpha': 0.08038093109575103}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:47:54,213] Trial 68 finished with value: 0.8219817100521988 and parameters: {'learning_rate': 0.019001005194990307, 'max_depth': 1, 'subsample': 0.9780576411286979, 'reg_lambda': 0.17276501364352295, 'reg_alpha': 0.0002788798721275525}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:47:59,325] Trial 69 finished with value: 0.8229064715744379 and parameters: {'learning_rate': 0.04842748550341278, 'max_depth': 1, 'subsample': 0.9033582192250643, 'reg_lambda': 0.02159933959727847, 'reg_alpha': 0.03696950830329481}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:48:04,452] Trial 70 finished with value: 0.8223675709878412 and parameters: {'learning_rate': 0.264818065608177, 'max_depth': 1, 'subsample': 0.9982326705632238, 'reg_lambda': 1.6875337255522553, 'reg_alpha': 0.002308732119227449}. Best is trial 55 with value: 0.8230878553752775.\n",
      "[I 2024-01-07 10:48:09,595] Trial 71 finished with value: 0.8233272626817737 and parameters: {'learning_rate': 0.1634158738934276, 'max_depth': 1, 'subsample': 0.9606241533355822, 'reg_lambda': 0.00908633153974636, 'reg_alpha': 0.03259605349244407}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:48:14,714] Trial 72 finished with value: 0.8228892802987626 and parameters: {'learning_rate': 0.15987433918718602, 'max_depth': 1, 'subsample': 0.9569247380249079, 'reg_lambda': 0.034180296290763065, 'reg_alpha': 0.009383473870720244}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:48:19,731] Trial 73 finished with value: 0.8230839867977737 and parameters: {'learning_rate': 0.07921910355996183, 'max_depth': 1, 'subsample': 0.9342296395397435, 'reg_lambda': 0.049799644129656664, 'reg_alpha': 0.017023272531039458}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:48:24,717] Trial 74 finished with value: 0.8224629842512126 and parameters: {'learning_rate': 0.12838786717485795, 'max_depth': 1, 'subsample': 0.937431545936469, 'reg_lambda': 0.04829479749797778, 'reg_alpha': 0.00553282183107312}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:48:29,743] Trial 75 finished with value: 0.8230183526769821 and parameters: {'learning_rate': 0.08438162724971555, 'max_depth': 1, 'subsample': 0.9136726084791724, 'reg_lambda': 0.009987197022411982, 'reg_alpha': 0.1384069843752715}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:48:34,909] Trial 76 finished with value: 0.0 and parameters: {'learning_rate': 0.0010751241002356947, 'max_depth': 1, 'subsample': 0.8735172869927932, 'reg_lambda': 0.008771549790520427, 'reg_alpha': 0.39936952304931334}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:48:39,869] Trial 77 finished with value: 0.8222198229478037 and parameters: {'learning_rate': 0.1646939928110072, 'max_depth': 1, 'subsample': 0.9143814787780344, 'reg_lambda': 0.003147893226979611, 'reg_alpha': 0.1396824747010458}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:48:44,953] Trial 78 finished with value: 0.8229365110845921 and parameters: {'learning_rate': 0.06405599586854725, 'max_depth': 1, 'subsample': 0.8583406643050961, 'reg_lambda': 0.03838631498507559, 'reg_alpha': 0.01816844961491345}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:48:49,968] Trial 79 finished with value: 0.8228950877973242 and parameters: {'learning_rate': 0.08760874050415057, 'max_depth': 1, 'subsample': 0.661491763267161, 'reg_lambda': 0.3274628201570264, 'reg_alpha': 0.07710009983226494}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:48:55,156] Trial 80 finished with value: 0.820571750603496 and parameters: {'learning_rate': 0.11629409710898472, 'max_depth': 3, 'subsample': 0.8937503738930663, 'reg_lambda': 0.010665830505176535, 'reg_alpha': 0.8575919135525925}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:49:00,211] Trial 81 finished with value: 0.8230597160811509 and parameters: {'learning_rate': 0.08099688787629226, 'max_depth': 1, 'subsample': 0.9587732175717759, 'reg_lambda': 0.014991875563481602, 'reg_alpha': 0.039970741660652474}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:49:05,344] Trial 82 finished with value: 0.8230093800739937 and parameters: {'learning_rate': 0.11371942733715826, 'max_depth': 1, 'subsample': 0.931487795253555, 'reg_lambda': 0.08231783085160348, 'reg_alpha': 0.012223544665470688}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:49:10,540] Trial 83 finished with value: 0.8230145594930547 and parameters: {'learning_rate': 0.08520066173615208, 'max_depth': 1, 'subsample': 0.9276121070803706, 'reg_lambda': 0.07857743157455171, 'reg_alpha': 0.04659860347795676}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:49:15,710] Trial 84 finished with value: 0.8227570945807144 and parameters: {'learning_rate': 0.0378488369162792, 'max_depth': 1, 'subsample': 0.9611719661198627, 'reg_lambda': 0.006516310040490273, 'reg_alpha': 0.03839544233852599}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:49:20,909] Trial 85 finished with value: 0.8231205347846593 and parameters: {'learning_rate': 0.08533046338958668, 'max_depth': 1, 'subsample': 0.9527922118676545, 'reg_lambda': 0.08671452455505395, 'reg_alpha': 0.06977602103713398}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:49:25,984] Trial 86 finished with value: 0.8228043975124648 and parameters: {'learning_rate': 0.043898966475947133, 'max_depth': 1, 'subsample': 0.9115950451810075, 'reg_lambda': 0.1321188633974736, 'reg_alpha': 0.17063852759031614}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:49:31,036] Trial 87 finished with value: 0.8229963858725571 and parameters: {'learning_rate': 0.06217794106304331, 'max_depth': 1, 'subsample': 0.9510685788197566, 'reg_lambda': 0.00470587085234978, 'reg_alpha': 0.07047295803509689}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:49:36,031] Trial 88 finished with value: 0.8223195239062937 and parameters: {'learning_rate': 0.18100997798297697, 'max_depth': 1, 'subsample': 0.9872356673340581, 'reg_lambda': 0.045532218509389155, 'reg_alpha': 0.0315234892278491}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:49:41,089] Trial 89 finished with value: 0.8218486044226498 and parameters: {'learning_rate': 0.14543208625969634, 'max_depth': 1, 'subsample': 0.8922665048198278, 'reg_lambda': 0.014971960888761538, 'reg_alpha': 0.010062517019305514}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:49:46,146] Trial 90 finished with value: 0.0 and parameters: {'learning_rate': 0.0038263171789972763, 'max_depth': 1, 'subsample': 0.9472778862420881, 'reg_lambda': 0.580067277160129, 'reg_alpha': 0.015241318431602244}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:49:51,219] Trial 91 finished with value: 0.8230968044388384 and parameters: {'learning_rate': 0.08376455964087352, 'max_depth': 1, 'subsample': 0.9216064868801603, 'reg_lambda': 0.09019891683470603, 'reg_alpha': 0.05066097201630171}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:49:56,206] Trial 92 finished with value: 0.8228835777294274 and parameters: {'learning_rate': 0.06625696328123735, 'max_depth': 1, 'subsample': 0.9195717260798507, 'reg_lambda': 0.026068384597359506, 'reg_alpha': 0.057288802993278216}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:50:01,223] Trial 93 finished with value: 0.8231123646698775 and parameters: {'learning_rate': 0.08362041351085873, 'max_depth': 1, 'subsample': 0.9615158349890449, 'reg_lambda': 0.25841637103779463, 'reg_alpha': 0.005774466228169788}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:50:06,366] Trial 94 finished with value: 0.8231945492913608 and parameters: {'learning_rate': 0.23267607400051668, 'max_depth': 1, 'subsample': 0.9626148637792695, 'reg_lambda': 0.1699283211998003, 'reg_alpha': 0.005829283155431555}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:50:11,475] Trial 95 finished with value: 0.8217225594550175 and parameters: {'learning_rate': 0.2169942822576804, 'max_depth': 1, 'subsample': 0.9637902097430384, 'reg_lambda': 0.17877104429620216, 'reg_alpha': 0.0047650322932042575}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:50:16,530] Trial 96 finished with value: 0.821146492840007 and parameters: {'learning_rate': 0.3173045368666312, 'max_depth': 1, 'subsample': 0.9848410579717324, 'reg_lambda': 0.3062650502127095, 'reg_alpha': 0.027947450619839026}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:50:21,558] Trial 97 finished with value: 0.821218407156742 and parameters: {'learning_rate': 0.5159151119481368, 'max_depth': 1, 'subsample': 0.6230779277289769, 'reg_lambda': 1.2216270192359875, 'reg_alpha': 0.00289334325662703}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:50:26,853] Trial 98 finished with value: 0.8204599989401853 and parameters: {'learning_rate': 0.10726926998499468, 'max_depth': 3, 'subsample': 0.9514587492158013, 'reg_lambda': 0.22558797123118524, 'reg_alpha': 0.09755425281496861}. Best is trial 71 with value: 0.8233272626817737.\n",
      "[I 2024-01-07 10:50:31,892] Trial 99 finished with value: 0.8220112127301713 and parameters: {'learning_rate': 0.1412053937923456, 'max_depth': 1, 'subsample': 0.9870185760272829, 'reg_lambda': 0.4925737711322074, 'reg_alpha': 0.021044756600117853}. Best is trial 71 with value: 0.8233272626817737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-07 10:50:31,894: 92: logger: INFO: common:  json file saved at: logs/XGBClassifier.json]\n",
      "[2024-01-07 10:50:33,915: 149: logger: INFO: stacking_model_training:  Model XGBClassifier has been tuned]\n",
      "[2024-01-07 10:50:33,917: 188: logger: INFO: stacking_model_training:  === FINISHED TRAINING STAGE for stacking models ===]\n",
      "CPU times: user 43.3 s, sys: 10.2 s, total: 53.6 s\n",
      "Wall time: 8min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "component = StackingModelTraining(stacking_model_training_config, config_manager.config.path,\n",
    "                                  models=['XGBClassifier'])\n",
    "component.run_stage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dceec1bb-fef5-4091-a509-5195ab87c2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-06 22:55:40,794: 47: logger: INFO: common:  yaml file: src/params/polySVC.yaml loaded successfully]\n",
      "[2024-01-06 22:55:40,795: 173: logger: INFO: stacking_model_training:  === STARTING TRAINING STAGE for stacking models ===]\n",
      "[2024-01-06 22:55:40,809: 171: logger: INFO: common:  tensor file has been loaded from: data/target]\n",
      "[2024-01-06 22:55:43,468: 177: logger: INFO: stacking_model_training:  Part1. Target data has been loaded]\n",
      "[2024-01-06 22:55:43,551: 182: logger: INFO: stacking_model_training:  Part2. First level logits have been loaded]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49cec9053eb44ac3b8c0e0cc0eac7cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tuning Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 22:55:43,560] A new study created in memory with name: no-name-973517fe-cced-4de8-8ec1-ea7a8fa3a7a5\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:56:00,875] Trial 0 finished with value: 0.5482621470618285 and parameters: {'gamma': 'auto', 'degree': 2, 'C': 2.550264850403285e-05}. Best is trial 0 with value: 0.5482621470618285.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:56:17,523] Trial 1 finished with value: 0.15789805000530538 and parameters: {'gamma': 'scale', 'degree': 4, 'C': 0.00030645998412411475}. Best is trial 0 with value: 0.5482621470618285.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:56:34,730] Trial 2 finished with value: 0.47296199560881336 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 0.19185373703841915}. Best is trial 0 with value: 0.5482621470618285.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:56:51,632] Trial 3 finished with value: 0.47898953931782373 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.039777828308111905}. Best is trial 0 with value: 0.5482621470618285.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:57:06,935] Trial 4 finished with value: 0.1650823497695589 and parameters: {'gamma': 'scale', 'degree': 5, 'C': 57.46775499181863}. Best is trial 0 with value: 0.5482621470618285.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:57:22,874] Trial 5 finished with value: 0.4844303516860632 and parameters: {'gamma': 'scale', 'degree': 3, 'C': 0.029257577949824417}. Best is trial 0 with value: 0.5482621470618285.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:57:38,809] Trial 6 finished with value: 0.555118930453341 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 0.06713854967599221}. Best is trial 6 with value: 0.555118930453341.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:57:54,535] Trial 7 finished with value: 0.3899448123854301 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 28.387009634436275}. Best is trial 6 with value: 0.555118930453341.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:58:10,961] Trial 8 finished with value: 0.5597308167925664 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 6.326486185661585}. Best is trial 8 with value: 0.5597308167925664.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:58:26,816] Trial 9 finished with value: 0.15789805000530538 and parameters: {'gamma': 'scale', 'degree': 4, 'C': 80.9484535228614}. Best is trial 8 with value: 0.5597308167925664.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:58:42,731] Trial 10 finished with value: 0.46445467829361975 and parameters: {'gamma': 'auto', 'degree': 2, 'C': 0.9061865093854703}. Best is trial 8 with value: 0.5597308167925664.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:58:59,168] Trial 11 finished with value: 0.15214320782536972 and parameters: {'gamma': 'auto', 'degree': 5, 'C': 1.9052645851439751}. Best is trial 8 with value: 0.5597308167925664.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:59:15,944] Trial 12 finished with value: 0.30957822981432254 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 0.0022058005138799164}. Best is trial 8 with value: 0.5597308167925664.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:59:32,146] Trial 13 finished with value: 0.643750697403394 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 2.845269624297687}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:59:48,457] Trial 14 finished with value: 0.4840192725840098 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 4.282024870369451}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:00:04,602] Trial 15 finished with value: 0.48390340907447427 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 7.901685002324064}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:00:21,321] Trial 16 finished with value: 0.5592379096265824 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.4617784699943037}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:00:37,466] Trial 17 finished with value: 0.4839984577855438 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.004389954284791985}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:00:53,615] Trial 18 finished with value: 0.15793828320030268 and parameters: {'gamma': 'scale', 'degree': 4, 'C': 7.707960414354007}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:01:08,971] Trial 19 finished with value: 0.46445467829361975 and parameters: {'gamma': 'auto', 'degree': 2, 'C': 0.332174649002213}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:01:26,595] Trial 20 finished with value: 0.3152183328768971 and parameters: {'gamma': 'auto', 'degree': 5, 'C': 15.51810745738041}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:01:41,983] Trial 21 finished with value: 0.5598570821965878 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.6288285581612403}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:01:58,408] Trial 22 finished with value: 0.6367807328864995 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 1.5281188669511863}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:02:14,600] Trial 23 finished with value: 0.6429323621970471 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 1.507486862317278}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:02:31,154] Trial 24 finished with value: 0.48390260402121116 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 1.541957267670439}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:02:48,046] Trial 25 finished with value: 0.6429008182865052 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.10140086090152851}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:03:03,621] Trial 26 finished with value: 0.15793828320030268 and parameters: {'gamma': 'scale', 'degree': 4, 'C': 0.13305675988118856}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:03:20,078] Trial 27 finished with value: 0.5586946017522032 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.02006098379688757}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:03:36,149] Trial 28 finished with value: 0.46445467829361975 and parameters: {'gamma': 'auto', 'degree': 2, 'C': 0.01421110310659959}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:03:51,981] Trial 29 finished with value: 0.24307846198177382 and parameters: {'gamma': 'auto', 'degree': 5, 'C': 0.0001910869462086695}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:04:07,305] Trial 30 finished with value: 0.3943146165122415 and parameters: {'gamma': 'auto', 'degree': 2, 'C': 1.2366719225667873e-05}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:04:23,392] Trial 31 finished with value: 0.559354578189381 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 2.1158171910735066}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:04:40,355] Trial 32 finished with value: 0.5597650081524898 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.13209408008598245}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:04:56,517] Trial 33 finished with value: 0.45291079302614523 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 2.3105838868845994}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:05:12,856] Trial 34 finished with value: 0.4814407546561035 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.1575481494608646}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:05:29,035] Trial 35 finished with value: 0.15789805000530538 and parameters: {'gamma': 'scale', 'degree': 4, 'C': 24.815274038895875}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:05:45,652] Trial 36 finished with value: 0.4839984577855438 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.006638835479461922}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:06:01,505] Trial 37 finished with value: 0.559354578189381 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.31121020452032927}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:06:17,515] Trial 38 finished with value: 0.16553299084197873 and parameters: {'gamma': 'scale', 'degree': 5, 'C': 0.06835397501156949}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:06:32,984] Trial 39 finished with value: 0.22481198345447412 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 0.0009784109577789632}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:06:49,431] Trial 40 finished with value: 0.6367807328864995 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.9368835627370152}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:07:04,989] Trial 41 finished with value: 0.48400395787461764 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 1.130778080958828}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:07:20,649] Trial 42 finished with value: 0.6401382871343283 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 3.3195755264114255}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:07:37,140] Trial 43 finished with value: 0.5598239813551587 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 4.047458776722558}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:07:53,953] Trial 44 finished with value: 0.48076237391394405 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 13.333337771370505}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:08:09,579] Trial 45 finished with value: 0.4729646826046353 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 0.060205111979687004}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:08:25,458] Trial 46 finished with value: 0.15793828320030268 and parameters: {'gamma': 'scale', 'degree': 4, 'C': 38.190241709594446}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:08:41,731] Trial 47 finished with value: 0.6421410860694124 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 4.141259441219358}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:08:58,197] Trial 48 finished with value: 0.46445467829361975 and parameters: {'gamma': 'auto', 'degree': 2, 'C': 4.942221468626286}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:09:14,803] Trial 49 finished with value: 0.4752671453489658 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 86.68033875456}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:09:30,584] Trial 50 finished with value: 0.6425537719667793 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 3.1248043513544346}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:09:46,415] Trial 51 finished with value: 0.3934431990031677 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 11.883555207804758}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:10:02,289] Trial 52 finished with value: 0.5585328968543914 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 3.370781758080324}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:10:18,243] Trial 53 finished with value: 0.4730034122578443 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 0.5434625182857192}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:10:33,344] Trial 54 finished with value: 0.39401984439882876 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 8.176693359274276}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:10:49,948] Trial 55 finished with value: 0.16063947185522354 and parameters: {'gamma': 'auto', 'degree': 5, 'C': 22.693986227681567}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:11:07,238] Trial 56 finished with value: 0.55970731279236 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 2.5104417445859437}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:11:24,068] Trial 57 finished with value: 0.4844440412575113 and parameters: {'gamma': 'scale', 'degree': 3, 'C': 42.874075078013}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:11:40,447] Trial 58 finished with value: 0.5585528830505858 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.2721226370114396}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:11:57,337] Trial 59 finished with value: 0.4806140316853824 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.714878776864528}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:12:13,434] Trial 60 finished with value: 0.46445467829361975 and parameters: {'gamma': 'auto', 'degree': 2, 'C': 7.717502877542221}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:12:29,740] Trial 61 finished with value: 0.4873813864744747 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 1.5334921915062691}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:12:45,891] Trial 62 finished with value: 0.55970731279236 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 1.4210707498103927}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:13:02,283] Trial 63 finished with value: 0.6386243356730326 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 4.864864163541738}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:13:18,801] Trial 64 finished with value: 0.47788537257780067 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 3.2872301006595093}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:13:35,676] Trial 65 finished with value: 0.48366426244111144 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 17.457515005137445}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:13:52,040] Trial 66 finished with value: 0.5597308167925664 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 5.632489340554301}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:14:08,772] Trial 67 finished with value: 0.643750697403394 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 10.360406447129673}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:14:25,057] Trial 68 finished with value: 0.3181460194015114 and parameters: {'gamma': 'auto', 'degree': 5, 'C': 8.696636901607986}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:14:41,320] Trial 69 finished with value: 0.15789805000530538 and parameters: {'gamma': 'scale', 'degree': 4, 'C': 47.2235293216864}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:14:58,194] Trial 70 finished with value: 0.6388536555503155 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.36006645901249584}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:15:14,033] Trial 71 finished with value: 0.5592379096265824 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.4474115131307506}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:15:31,852] Trial 72 finished with value: 0.6394050675169173 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.0877738904590116}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:15:48,671] Trial 73 finished with value: 0.4839984577855438 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.010442800797630155}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:16:04,862] Trial 74 finished with value: 0.47898953931782373 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.022822104480603605}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:16:21,554] Trial 75 finished with value: 0.6394050675169173 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.04092334779099402}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:16:37,748] Trial 76 finished with value: 0.5572024160999017 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 0.09784878914405734}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:16:53,498] Trial 77 finished with value: 0.5599885535770648 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.21894343545189185}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:17:09,474] Trial 78 finished with value: 0.21923074501720732 and parameters: {'gamma': 'auto', 'degree': 2, 'C': 6.384665812783202e-05}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:17:25,516] Trial 79 finished with value: 0.48449797371691883 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.8503526094262196}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:17:42,338] Trial 80 finished with value: 0.15789805000530538 and parameters: {'gamma': 'scale', 'degree': 4, 'C': 2.124407456379863}. Best is trial 13 with value: 0.643750697403394.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:17:58,436] Trial 81 finished with value: 0.6456640075155878 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.04339122673042168}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:18:15,180] Trial 82 finished with value: 0.47898953931782373 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.040370674423547914}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:18:31,466] Trial 83 finished with value: 0.4839984577855438 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.002045306204652788}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:18:48,309] Trial 84 finished with value: 0.5571238985362142 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.08855182317498077}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:19:05,491] Trial 85 finished with value: 0.47776870401500204 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 12.088986364429935}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:19:21,416] Trial 86 finished with value: 0.47231219134013547 and parameters: {'gamma': 'auto', 'degree': 5, 'C': 0.014566811541913686}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:19:37,686] Trial 87 finished with value: 0.5569124145084052 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 2.4632213156930005}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:19:54,072] Trial 88 finished with value: 0.48344439862207045 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.20036114384752401}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:20:10,148] Trial 89 finished with value: 0.5592379096265824 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 1.3406961178450574}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:20:27,557] Trial 90 finished with value: 0.48024080483319564 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 3.6420177769939683}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:20:44,134] Trial 91 finished with value: 0.47898953931782373 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.028129684835000147}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:21:00,965] Trial 92 finished with value: 0.4839984577855438 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.007215980473214158}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:21:17,153] Trial 93 finished with value: 0.6394050675169173 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.048099069102281365}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:21:33,270] Trial 94 finished with value: 0.6394050675169173 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.08352138546736525}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:21:50,148] Trial 95 finished with value: 0.4795533127240038 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 0.12714777350369638}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:22:06,827] Trial 96 finished with value: 0.5561277132404152 and parameters: {'gamma': 'auto', 'degree': 3, 'C': 0.031309644524069265}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:22:23,120] Trial 97 finished with value: 0.46445467829361975 and parameters: {'gamma': 'auto', 'degree': 2, 'C': 0.05166495878966434}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:22:38,975] Trial 98 finished with value: 0.15789805000530538 and parameters: {'gamma': 'scale', 'degree': 4, 'C': 30.258384324263663}. Best is trial 81 with value: 0.6456640075155878.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 23:22:55,190] Trial 99 finished with value: 0.6428680806640455 and parameters: {'gamma': 'auto', 'degree': 4, 'C': 19.62347795699169}. Best is trial 81 with value: 0.6456640075155878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-06 23:22:55,192: 92: logger: INFO: common:  json file saved at: logs/polySVC.json]\n",
      "[2024-01-06 23:23:07,680: 148: logger: INFO: stacking_model_training:  Model polySVC has been tuned]\n",
      "[2024-01-06 23:23:07,682: 187: logger: INFO: stacking_model_training:  === FINISHED TRAINING STAGE for stacking models ===]\n",
      "CPU times: user 58.3 s, sys: 12.8 s, total: 1min 11s\n",
      "Wall time: 27min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "component = StackingModelTraining(stacking_model_training_config, config_manager.config.path,\n",
    "                                  models=['polySVC'])\n",
    "component.run_stage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4444666-9e25-41ad-8e8c-94dbaaed2fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-06 22:13:12,755: 47: logger: INFO: common:  yaml file: src/params/rbfSVC.yaml loaded successfully]\n",
      "[2024-01-06 22:13:12,757: 173: logger: INFO: stacking_model_training:  === STARTING TRAINING STAGE for stacking models ===]\n",
      "[2024-01-06 22:13:12,792: 171: logger: INFO: common:  tensor file has been loaded from: data/target]\n",
      "[2024-01-06 22:13:15,503: 177: logger: INFO: stacking_model_training:  Part1. Target data has been loaded]\n",
      "[2024-01-06 22:13:15,628: 182: logger: INFO: stacking_model_training:  Part2. First level logits have been loaded]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d33b7b8cf0a4bb8952172e944f50a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tuning Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 22:13:15,637] A new study created in memory with name: no-name-4212d5c2-2793-4871-9698-e81072bd9566\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:13:39,798] Trial 0 finished with value: 0.8165482573771907 and parameters: {'gamma': 'auto', 'C': 2.465832945854912}. Best is trial 0 with value: 0.8165482573771907.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:14:03,534] Trial 1 finished with value: 0.25293555306684246 and parameters: {'gamma': 'scale', 'C': 0.0008629132190071859}. Best is trial 0 with value: 0.8165482573771907.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:14:27,392] Trial 2 finished with value: 0.661966864053754 and parameters: {'gamma': 'auto', 'C': 0.4042872735027334}. Best is trial 0 with value: 0.8165482573771907.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:14:51,358] Trial 3 finished with value: 0.0705256050405226 and parameters: {'gamma': 'scale', 'C': 65.98711072054076}. Best is trial 0 with value: 0.8165482573771907.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:15:14,384] Trial 4 finished with value: 0.0781683209691861 and parameters: {'gamma': 'scale', 'C': 0.0012329623163659848}. Best is trial 0 with value: 0.8165482573771907.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:15:37,293] Trial 5 finished with value: 0.6401046276974736 and parameters: {'gamma': 'auto', 'C': 0.14077923139972406}. Best is trial 0 with value: 0.8165482573771907.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:16:01,001] Trial 6 finished with value: 0.07664081295746236 and parameters: {'gamma': 'scale', 'C': 0.4689400963537689}. Best is trial 0 with value: 0.8165482573771907.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:16:24,405] Trial 7 finished with value: 0.82292483974526 and parameters: {'gamma': 'auto', 'C': 0.01578232781079559}. Best is trial 7 with value: 0.82292483974526.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:16:47,261] Trial 8 finished with value: 0.4692863362303071 and parameters: {'gamma': 'auto', 'C': 0.0015777663630582469}. Best is trial 7 with value: 0.82292483974526.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:17:10,634] Trial 9 finished with value: 0.6661577625060672 and parameters: {'gamma': 'auto', 'C': 0.0001899776347411129}. Best is trial 7 with value: 0.82292483974526.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:17:34,130] Trial 10 finished with value: 0.8217469017273569 and parameters: {'gamma': 'auto', 'C': 0.015218296516412629}. Best is trial 7 with value: 0.82292483974526.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:17:58,193] Trial 11 finished with value: 0.8223634741815615 and parameters: {'gamma': 'auto', 'C': 0.012053282859112384}. Best is trial 7 with value: 0.82292483974526.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:18:21,577] Trial 12 finished with value: 0.6579001003792513 and parameters: {'gamma': 'auto', 'C': 0.015937888082174775}. Best is trial 7 with value: 0.82292483974526.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:18:44,363] Trial 13 finished with value: 0.4844200989790471 and parameters: {'gamma': 'auto', 'C': 0.012155404044433098}. Best is trial 7 with value: 0.82292483974526.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:19:08,274] Trial 14 finished with value: 0.6448608983095299 and parameters: {'gamma': 'auto', 'C': 0.041351614541882936}. Best is trial 7 with value: 0.82292483974526.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:19:31,723] Trial 15 finished with value: 0.8204393304508326 and parameters: {'gamma': 'auto', 'C': 4.511388495675228}. Best is trial 7 with value: 0.82292483974526.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:19:55,235] Trial 16 finished with value: 0.32710420539060103 and parameters: {'gamma': 'auto', 'C': 0.005382575559999453}. Best is trial 7 with value: 0.82292483974526.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:20:18,273] Trial 17 finished with value: 0.82337868807582 and parameters: {'gamma': 'auto', 'C': 0.00018497828848075047}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:20:41,356] Trial 18 finished with value: 0.07241827366358866 and parameters: {'gamma': 'scale', 'C': 0.00010848699617221559}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:21:04,956] Trial 19 finished with value: 0.8214332116601869 and parameters: {'gamma': 'auto', 'C': 0.000295863413067451}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:21:28,105] Trial 20 finished with value: 0.8192681915904254 and parameters: {'gamma': 'auto', 'C': 0.002785143811677732}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:21:51,975] Trial 21 finished with value: 0.8213335726379833 and parameters: {'gamma': 'auto', 'C': 0.07601883822786636}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:22:15,276] Trial 22 finished with value: 0.8147950073589174 and parameters: {'gamma': 'auto', 'C': 0.0006171478927677503}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:22:37,953] Trial 23 finished with value: 0.47696318794901266 and parameters: {'gamma': 'auto', 'C': 0.007111921334116706}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:23:01,243] Trial 24 finished with value: 0.48344191028943295 and parameters: {'gamma': 'auto', 'C': 0.05486054780596607}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:23:24,496] Trial 25 finished with value: 0.8226347795926868 and parameters: {'gamma': 'auto', 'C': 0.25826028547887653}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:23:47,734] Trial 26 finished with value: 0.2473395985816878 and parameters: {'gamma': 'scale', 'C': 1.2916940292914565}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:24:10,284] Trial 27 finished with value: 0.6561352684995905 and parameters: {'gamma': 'auto', 'C': 72.91770085987083}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:24:33,848] Trial 28 finished with value: 0.8227322302283977 and parameters: {'gamma': 'auto', 'C': 19.75511373997311}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:24:57,081] Trial 29 finished with value: 0.8196636015857695 and parameters: {'gamma': 'auto', 'C': 12.48460345029723}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:25:20,723] Trial 30 finished with value: 0.6478124449197324 and parameters: {'gamma': 'auto', 'C': 25.25423773979225}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:25:45,119] Trial 31 finished with value: 0.819900834025275 and parameters: {'gamma': 'auto', 'C': 3.8291940985789306}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:26:08,572] Trial 32 finished with value: 0.8204648790699757 and parameters: {'gamma': 'auto', 'C': 0.3145683703269138}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:26:32,577] Trial 33 finished with value: 0.8210006600087901 and parameters: {'gamma': 'auto', 'C': 0.6983222750001024}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:26:54,886] Trial 34 finished with value: 0.07689229375824418 and parameters: {'gamma': 'scale', 'C': 0.18791924165875504}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:27:18,409] Trial 35 finished with value: 0.8185872622902064 and parameters: {'gamma': 'auto', 'C': 9.225765307707263}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:27:42,298] Trial 36 finished with value: 0.8228061537976673 and parameters: {'gamma': 'auto', 'C': 0.0331652623612511}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:28:05,597] Trial 37 finished with value: 0.24992582866472843 and parameters: {'gamma': 'scale', 'C': 0.0005980611105776176}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:28:29,280] Trial 38 finished with value: 0.8163562818972596 and parameters: {'gamma': 'auto', 'C': 0.033822995560396384}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:28:52,299] Trial 39 finished with value: 0.24992582866472843 and parameters: {'gamma': 'scale', 'C': 0.003484834852380613}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:29:16,318] Trial 40 finished with value: 0.8219996136249533 and parameters: {'gamma': 'auto', 'C': 1.3760228782128199}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:29:38,928] Trial 41 finished with value: 0.6564782890454 and parameters: {'gamma': 'auto', 'C': 0.025496286384709754}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:30:02,670] Trial 42 finished with value: 0.6504679620515064 and parameters: {'gamma': 'auto', 'C': 0.1603722795017391}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:30:25,968] Trial 43 finished with value: 0.6453978850076095 and parameters: {'gamma': 'auto', 'C': 0.0015805862671461608}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:30:49,180] Trial 44 finished with value: 0.8231277786529795 and parameters: {'gamma': 'auto', 'C': 0.2575987518655636}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:31:12,756] Trial 45 finished with value: 0.8132312767953472 and parameters: {'gamma': 'auto', 'C': 24.033193838810835}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:31:35,695] Trial 46 finished with value: 0.47068091462438705 and parameters: {'gamma': 'auto', 'C': 0.10662380402636289}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:31:59,197] Trial 47 finished with value: 0.8195945631821541 and parameters: {'gamma': 'auto', 'C': 0.02459504976371361}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:32:21,911] Trial 48 finished with value: 0.6435903871742475 and parameters: {'gamma': 'auto', 'C': 0.934802923207556}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:32:44,336] Trial 49 finished with value: 0.6640744594952426 and parameters: {'gamma': 'auto', 'C': 0.007618860175572748}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:33:06,653] Trial 50 finished with value: 0.25142428290999963 and parameters: {'gamma': 'scale', 'C': 0.0002858284188971056}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:33:29,405] Trial 51 finished with value: 0.8208002420228434 and parameters: {'gamma': 'auto', 'C': 0.46522546284753563}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:33:52,566] Trial 52 finished with value: 0.8221607913066525 and parameters: {'gamma': 'auto', 'C': 0.05906716808455436}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:34:14,782] Trial 53 finished with value: 0.8208080400516509 and parameters: {'gamma': 'auto', 'C': 0.2553701703325543}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:34:37,559] Trial 54 finished with value: 0.6519495668614926 and parameters: {'gamma': 'auto', 'C': 1.8763208908638083}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:35:00,282] Trial 55 finished with value: 0.8229554541390594 and parameters: {'gamma': 'auto', 'C': 0.10065644751609569}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:35:24,297] Trial 56 finished with value: 0.29739752045343 and parameters: {'gamma': 'auto', 'C': 0.0979544860082839}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:35:47,082] Trial 57 finished with value: 0.8225360269610725 and parameters: {'gamma': 'auto', 'C': 0.021104520387790728}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:36:10,470] Trial 58 finished with value: 0.6552498552709634 and parameters: {'gamma': 'auto', 'C': 0.01029556293375494}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:36:34,452] Trial 59 finished with value: 0.8187346117645901 and parameters: {'gamma': 'auto', 'C': 0.00010296938408790568}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:36:57,082] Trial 60 finished with value: 0.8219594363725634 and parameters: {'gamma': 'auto', 'C': 0.0023783116541965677}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:37:20,036] Trial 61 finished with value: 0.642050453113784 and parameters: {'gamma': 'auto', 'C': 0.04706371890472864}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:37:42,998] Trial 62 finished with value: 0.8233074306410021 and parameters: {'gamma': 'auto', 'C': 0.26659867360261685}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:38:05,906] Trial 63 finished with value: 0.6424121881752751 and parameters: {'gamma': 'auto', 'C': 0.514148900922961}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:38:28,879] Trial 64 finished with value: 0.6567276386389369 and parameters: {'gamma': 'auto', 'C': 0.11767405752211067}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:38:51,720] Trial 65 finished with value: 0.8206847112490937 and parameters: {'gamma': 'auto', 'C': 3.5901350789093818}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:39:17,286] Trial 66 finished with value: 0.662935681058033 and parameters: {'gamma': 'auto', 'C': 0.07130297461560044}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:39:40,712] Trial 67 finished with value: 0.07251724204827327 and parameters: {'gamma': 'scale', 'C': 96.56482791446278}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:40:03,691] Trial 68 finished with value: 0.6407345022037929 and parameters: {'gamma': 'auto', 'C': 0.0048901139526853704}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:40:26,506] Trial 69 finished with value: 0.5146141335238716 and parameters: {'gamma': 'auto', 'C': 0.0009834884287286518}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:40:49,446] Trial 70 finished with value: 0.8178839018365375 and parameters: {'gamma': 'auto', 'C': 34.35833985379993}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:41:12,686] Trial 71 finished with value: 0.6589336464104885 and parameters: {'gamma': 'auto', 'C': 0.19562006679229313}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:41:35,906] Trial 72 finished with value: 0.8177191648346483 and parameters: {'gamma': 'auto', 'C': 0.7707845775984764}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:41:59,330] Trial 73 finished with value: 0.6450981124502195 and parameters: {'gamma': 'auto', 'C': 0.3019274868682099}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:42:22,052] Trial 74 finished with value: 0.8189576590662105 and parameters: {'gamma': 'auto', 'C': 7.188410088725643}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:42:45,197] Trial 75 finished with value: 0.6506902571594172 and parameters: {'gamma': 'auto', 'C': 0.03785066783100875}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:43:08,073] Trial 76 finished with value: 0.8214305954360196 and parameters: {'gamma': 'auto', 'C': 0.2289623533600593}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:43:33,096] Trial 77 finished with value: 0.24660620050170126 and parameters: {'gamma': 'scale', 'C': 0.01769361612785507}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:43:56,173] Trial 78 finished with value: 0.2916547079554045 and parameters: {'gamma': 'auto', 'C': 0.36179633015002405}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:44:19,687] Trial 79 finished with value: 0.4876625892928793 and parameters: {'gamma': 'auto', 'C': 0.09312842530979937}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:44:43,374] Trial 80 finished with value: 0.820274575468664 and parameters: {'gamma': 'auto', 'C': 0.13373471710589366}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:45:06,947] Trial 81 finished with value: 0.6642051109681261 and parameters: {'gamma': 'auto', 'C': 0.021283874235966813}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:45:30,411] Trial 82 finished with value: 0.8212846644263153 and parameters: {'gamma': 'auto', 'C': 0.03920777008083987}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:45:53,421] Trial 83 finished with value: 0.8203053538095519 and parameters: {'gamma': 'auto', 'C': 0.012113006487131131}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:46:16,310] Trial 84 finished with value: 0.8218135694536628 and parameters: {'gamma': 'auto', 'C': 0.0685657544590452}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:46:39,382] Trial 85 finished with value: 0.8160865307367194 and parameters: {'gamma': 'auto', 'C': 2.634174867593897}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:47:02,503] Trial 86 finished with value: 0.8223812735411591 and parameters: {'gamma': 'auto', 'C': 1.2999105499284362}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:47:26,591] Trial 87 finished with value: 0.6461393459675469 and parameters: {'gamma': 'auto', 'C': 0.02796434977896342}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:47:49,929] Trial 88 finished with value: 0.8217510565622765 and parameters: {'gamma': 'auto', 'C': 0.00018772821886906278}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:48:13,774] Trial 89 finished with value: 0.24528093705929405 and parameters: {'gamma': 'scale', 'C': 0.5449689942149191}. Best is trial 17 with value: 0.82337868807582.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:48:37,276] Trial 90 finished with value: 0.8234446753231405 and parameters: {'gamma': 'auto', 'C': 0.008721969563313689}. Best is trial 90 with value: 0.8234446753231405.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:49:00,178] Trial 91 finished with value: 0.8207425248921871 and parameters: {'gamma': 'auto', 'C': 0.008498222187278089}. Best is trial 90 with value: 0.8234446753231405.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:49:23,677] Trial 92 finished with value: 0.8221825404510404 and parameters: {'gamma': 'auto', 'C': 0.014910267199610586}. Best is trial 90 with value: 0.8234446753231405.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:49:46,677] Trial 93 finished with value: 0.6640891008051748 and parameters: {'gamma': 'auto', 'C': 0.003879583565981322}. Best is trial 90 with value: 0.8234446753231405.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:50:09,715] Trial 94 finished with value: 0.8220237788686399 and parameters: {'gamma': 'auto', 'C': 0.0005298839789605328}. Best is trial 90 with value: 0.8234446753231405.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:50:33,076] Trial 95 finished with value: 0.8211671336009019 and parameters: {'gamma': 'auto', 'C': 0.04846655145223472}. Best is trial 90 with value: 0.8234446753231405.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:50:56,441] Trial 96 finished with value: 0.47966490613607665 and parameters: {'gamma': 'auto', 'C': 0.02976905396211666}. Best is trial 90 with value: 0.8234446753231405.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:51:19,409] Trial 97 finished with value: 0.822574781440582 and parameters: {'gamma': 'auto', 'C': 0.00596660270410347}. Best is trial 90 with value: 0.8234446753231405.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:51:41,980] Trial 98 finished with value: 0.8239949847143413 and parameters: {'gamma': 'auto', 'C': 0.0021051789348473164}. Best is trial 98 with value: 0.8239949847143413.\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/BigDataProject/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-01-06 22:52:04,828] Trial 99 finished with value: 0.6563195597843703 and parameters: {'gamma': 'auto', 'C': 0.0017675240317503102}. Best is trial 98 with value: 0.8239949847143413.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-06 22:52:04,830: 92: logger: INFO: common:  json file saved at: logs/rbfSVC.json]\n",
      "[2024-01-06 22:52:20,732: 148: logger: INFO: stacking_model_training:  Model rbfSVC has been tuned]\n",
      "[2024-01-06 22:52:20,734: 187: logger: INFO: stacking_model_training:  === FINISHED TRAINING STAGE for stacking models ===]\n",
      "CPU times: user 1min 3s, sys: 13.3 s, total: 1min 17s\n",
      "Wall time: 39min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "component = StackingModelTraining(stacking_model_training_config, config_manager.config.path,\n",
    "                                  models=['rbfSVC'])\n",
    "component.run_stage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b52436bc-bfc1-4d8e-9ecd-eb2b4725e543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-06 21:22:58,076: 47: logger: INFO: common:  yaml file: src/params/RandomForestClassifier.yaml loaded successfully]\n",
      "[2024-01-06 21:22:58,077: 173: logger: INFO: stacking_model_training:  === STARTING TRAINING STAGE for stacking models ===]\n",
      "[2024-01-06 21:22:58,089: 171: logger: INFO: common:  tensor file has been loaded from: data/target]\n",
      "[2024-01-06 21:23:00,673: 177: logger: INFO: stacking_model_training:  Part1. Target data has been loaded]\n",
      "[2024-01-06 21:23:00,748: 182: logger: INFO: stacking_model_training:  Part2. First level logits have been loaded]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0c446b8b544eb5967d7702cc3fb2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tuning Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 21:23:00,757] A new study created in memory with name: no-name-e7ff5db5-cd8d-4af2-9da7-1618acc09f61\n",
      "[I 2024-01-06 21:23:17,982] Trial 0 finished with value: 0.8230294072176441 and parameters: {'n_estimators': 20, 'max_depth': 1}. Best is trial 0 with value: 0.8230294072176441.\n",
      "[I 2024-01-06 21:24:33,270] Trial 1 finished with value: 0.8197693612629015 and parameters: {'n_estimators': 50, 'max_depth': 3}. Best is trial 0 with value: 0.8230294072176441.\n",
      "[I 2024-01-06 21:25:19,768] Trial 2 finished with value: 0.8198196267885234 and parameters: {'n_estimators': 30, 'max_depth': 3}. Best is trial 0 with value: 0.8230294072176441.\n",
      "[I 2024-01-06 21:25:44,138] Trial 3 finished with value: 0.8230539719383227 and parameters: {'n_estimators': 30, 'max_depth': 1}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:26:19,754] Trial 4 finished with value: 0.8176060080442724 and parameters: {'n_estimators': 30, 'max_depth': 2}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:27:13,826] Trial 5 finished with value: 0.823006712233557 and parameters: {'n_estimators': 70, 'max_depth': 1}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:28:23,175] Trial 6 finished with value: 0.8176355637909711 and parameters: {'n_estimators': 60, 'max_depth': 2}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:29:02,447] Trial 7 finished with value: 0.8230426676966309 and parameters: {'n_estimators': 50, 'max_depth': 1}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:30:33,981] Trial 8 finished with value: 0.8197548114731171 and parameters: {'n_estimators': 60, 'max_depth': 3}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:31:34,920] Trial 9 finished with value: 0.8196281648967413 and parameters: {'n_estimators': 40, 'max_depth': 3}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:33:07,240] Trial 10 finished with value: 0.8180640653712694 and parameters: {'n_estimators': 80, 'max_depth': 2}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:33:39,016] Trial 11 finished with value: 0.822998205918714 and parameters: {'n_estimators': 40, 'max_depth': 1}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:34:25,936] Trial 12 finished with value: 0.8176536815459297 and parameters: {'n_estimators': 40, 'max_depth': 2}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:36:26,322] Trial 13 finished with value: 0.819894492119578 and parameters: {'n_estimators': 80, 'max_depth': 3}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:37:13,043] Trial 14 finished with value: 0.8229943003106903 and parameters: {'n_estimators': 60, 'max_depth': 1}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:38:34,230] Trial 15 finished with value: 0.8176234818640364 and parameters: {'n_estimators': 70, 'max_depth': 2}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:38:58,217] Trial 16 finished with value: 0.8178483087208366 and parameters: {'n_estimators': 20, 'max_depth': 2}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:39:56,554] Trial 17 finished with value: 0.8176591352306501 and parameters: {'n_estimators': 50, 'max_depth': 2}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:40:28,029] Trial 18 finished with value: 0.8193861358454717 and parameters: {'n_estimators': 20, 'max_depth': 3}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:42:13,471] Trial 19 finished with value: 0.8198454873190396 and parameters: {'n_estimators': 70, 'max_depth': 3}. Best is trial 3 with value: 0.8230539719383227.\n",
      "[I 2024-01-06 21:43:14,947] Trial 20 finished with value: 0.8229942718181337 and parameters: {'n_estimators': 80, 'max_depth': 1}. Best is trial 3 with value: 0.8230539719383227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-06 21:43:14,948: 92: logger: INFO: common:  json file saved at: logs/RandomForestClassifier.json]\n",
      "[2024-01-06 21:43:38,939: 148: logger: INFO: stacking_model_training:  Model RandomForestClassifier has been tuned]\n",
      "[2024-01-06 21:43:38,941: 187: logger: INFO: stacking_model_training:  === FINISHED TRAINING STAGE for stacking models ===]\n",
      "CPU times: user 38.1 s, sys: 5.44 s, total: 43.6 s\n",
      "Wall time: 20min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "component = StackingModelTraining(stacking_model_training_config, config_manager.config.path,\n",
    "                                  models=['RandomForestClassifier'])\n",
    "component.run_stage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b16b77f-5c6a-4fda-b9cc-50e2f555a501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-06 19:21:03,353: 47: logger: INFO: common:  yaml file: src/params/LogisticRegression.yaml loaded successfully]\n",
      "[2024-01-06 19:21:03,355: 161: logger: INFO: stacking_model_training:  === STARTING TRAINING STAGE for stacking models ===]\n",
      "[2024-01-06 19:21:03,389: 171: logger: INFO: common:  tensor file has been loaded from: data/target]\n",
      "[2024-01-06 19:21:05,904: 165: logger: INFO: stacking_model_training:  Part1. Target data has been loaded]\n",
      "[2024-01-06 19:21:06,019: 170: logger: INFO: stacking_model_training:  Part2. First level logits have been loaded]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7ae78b04c645a9bf0da5874c807ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tuning Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 19:21:06,028] A new study created in memory with name: no-name-a72ded92-0095-4875-b50c-fd575cb9cf98\n",
      "[I 2024-01-06 19:21:09,378] Trial 0 finished with value: 0.8199331016286436 and parameters: {'C': 0.017670169402947963}. Best is trial 0 with value: 0.8199331016286436.\n",
      "[I 2024-01-06 19:21:12,616] Trial 1 finished with value: 0.8199346630232547 and parameters: {'C': 50.61576888752309}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:15,740] Trial 2 finished with value: 0.8199346630232547 and parameters: {'C': 2.465832945854912}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:19,049] Trial 3 finished with value: 0.8199340689780718 and parameters: {'C': 0.39079671568228835}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:21,977] Trial 4 finished with value: 0.8198599598618301 and parameters: {'C': 0.0008632008168602544}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:24,943] Trial 5 finished with value: 0.8198602776664587 and parameters: {'C': 0.0008629132190071859}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:27,600] Trial 6 finished with value: 0.8196330315201229 and parameters: {'C': 0.00022310108018679258}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:30,593] Trial 7 finished with value: 0.8199346630232547 and parameters: {'C': 15.741890047456648}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:33,672] Trial 8 finished with value: 0.8199340689780718 and parameters: {'C': 0.4042872735027334}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:36,735] Trial 9 finished with value: 0.8199342117940851 and parameters: {'C': 1.7718847354806828}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:39,757] Trial 10 finished with value: 0.8199346630232547 and parameters: {'C': 75.33019084841482}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:42,621] Trial 11 finished with value: 0.8199346630232547 and parameters: {'C': 7.153293939051241}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:45,461] Trial 12 finished with value: 0.8199346630232547 and parameters: {'C': 74.88122652230464}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:48,627] Trial 13 finished with value: 0.8199342968805061 and parameters: {'C': 0.053539728077986376}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:51,725] Trial 14 finished with value: 0.8199346630232547 and parameters: {'C': 7.099749885151785}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:54,730] Trial 15 finished with value: 0.8199342117940851 and parameters: {'C': 1.3554280409043842}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:21:57,876] Trial 16 finished with value: 0.8199346630232547 and parameters: {'C': 21.555185438491794}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:01,191] Trial 17 finished with value: 0.8199325563735596 and parameters: {'C': 0.012385420496245022}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:04,132] Trial 18 finished with value: 0.8199346630232547 and parameters: {'C': 2.2785003542887967}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:07,207] Trial 19 finished with value: 0.8199336125939753 and parameters: {'C': 0.29384604688430443}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:10,353] Trial 20 finished with value: 0.8199346630232547 and parameters: {'C': 36.282639783793606}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:13,271] Trial 21 finished with value: 0.8199346630232547 and parameters: {'C': 10.477353691394551}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:16,273] Trial 22 finished with value: 0.8199346630232547 and parameters: {'C': 20.99476321383806}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:19,168] Trial 23 finished with value: 0.8199346630232547 and parameters: {'C': 3.163379815385609}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:22,354] Trial 24 finished with value: 0.8199346630232547 and parameters: {'C': 87.43124421054152}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:25,274] Trial 25 finished with value: 0.8199337495920428 and parameters: {'C': 0.854650817390786}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:28,219] Trial 26 finished with value: 0.8199346630232547 and parameters: {'C': 7.184254867848952}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:31,234] Trial 27 finished with value: 0.8199336192376631 and parameters: {'C': 0.11247276825679062}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:34,222] Trial 28 finished with value: 0.8199346630232547 and parameters: {'C': 31.031235590191823}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:37,210] Trial 29 finished with value: 0.8199332110888944 and parameters: {'C': 0.021162414884556172}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:40,006] Trial 30 finished with value: 0.8199346630232547 and parameters: {'C': 14.089231292905428}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:43,161] Trial 31 finished with value: 0.8199346630232547 and parameters: {'C': 99.23563925785268}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:45,984] Trial 32 finished with value: 0.8199346630232547 and parameters: {'C': 44.09945773516247}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:48,843] Trial 33 finished with value: 0.8199346630232547 and parameters: {'C': 4.021723186410091}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:51,995] Trial 34 finished with value: 0.8199346630232547 and parameters: {'C': 45.01452283666707}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:54,969] Trial 35 finished with value: 0.8199346630232547 and parameters: {'C': 13.787373489098755}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:22:57,796] Trial 36 finished with value: 0.8199337495920428 and parameters: {'C': 0.7059913935513833}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:00,774] Trial 37 finished with value: 0.8199346630232547 and parameters: {'C': 4.759902392127829}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:03,807] Trial 38 finished with value: 0.819914460062484 and parameters: {'C': 0.0033860558349043854}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:06,648] Trial 39 finished with value: 0.8199346630232547 and parameters: {'C': 47.662460847608315}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:09,497] Trial 40 finished with value: 0.8199346630232547 and parameters: {'C': 16.990986908031765}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:12,631] Trial 41 finished with value: 0.8199346630232547 and parameters: {'C': 8.366813312540526}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:15,442] Trial 42 finished with value: 0.8199346630232547 and parameters: {'C': 5.577655863258495}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:18,460] Trial 43 finished with value: 0.8199342117940851 and parameters: {'C': 1.53224488174809}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:21,536] Trial 44 finished with value: 0.8199346630232547 and parameters: {'C': 25.98340302802245}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:24,439] Trial 45 finished with value: 0.8199346630232547 and parameters: {'C': 54.51944581801983}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:27,332] Trial 46 finished with value: 0.8199336125939753 and parameters: {'C': 0.18893013851258}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:30,214] Trial 47 finished with value: 0.8199346630232547 and parameters: {'C': 3.0397214368624095}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:33,324] Trial 48 finished with value: 0.8199346630232547 and parameters: {'C': 8.973503359012314}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:36,195] Trial 49 finished with value: 0.8199346630232547 and parameters: {'C': 96.10407459414881}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:39,167] Trial 50 finished with value: 0.8199337495920428 and parameters: {'C': 1.0689856184322848}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:42,219] Trial 51 finished with value: 0.8199346630232547 and parameters: {'C': 24.038222736583705}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:45,367] Trial 52 finished with value: 0.8199346630232547 and parameters: {'C': 57.26174015140308}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:48,534] Trial 53 finished with value: 0.8199346630232547 and parameters: {'C': 13.699575501080279}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:51,244] Trial 54 finished with value: 0.8199346630232547 and parameters: {'C': 64.54402902475451}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:54,303] Trial 55 finished with value: 0.8199346630232547 and parameters: {'C': 28.530962512086038}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:57,199] Trial 56 finished with value: 0.8199346630232547 and parameters: {'C': 2.539724291544702}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:23:59,727] Trial 57 finished with value: 0.8197817697775027 and parameters: {'C': 0.00048585936525030905}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:24:02,433] Trial 58 finished with value: 0.8194300808662855 and parameters: {'C': 0.00011639521730508292}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:24:05,483] Trial 59 finished with value: 0.8199346630232547 and parameters: {'C': 18.648583947479736}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:24:08,493] Trial 60 finished with value: 0.8199346630232547 and parameters: {'C': 31.36924840772588}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:24:11,647] Trial 61 finished with value: 0.8199346630232547 and parameters: {'C': 6.195139398080777}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:24:14,759] Trial 62 finished with value: 0.8199346630232547 and parameters: {'C': 9.090940098757741}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:24:17,869] Trial 63 finished with value: 0.8199340689780718 and parameters: {'C': 0.3953766611073448}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:24:20,995] Trial 64 finished with value: 0.8199346630232547 and parameters: {'C': 73.45649663741057}. Best is trial 1 with value: 0.8199346630232547.\n",
      "[I 2024-01-06 19:24:24,122] Trial 65 finished with value: 0.819935714759596 and parameters: {'C': 0.04809281161055719}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:24:27,051] Trial 66 finished with value: 0.8199354317783876 and parameters: {'C': 0.040905640641944796}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:24:30,095] Trial 67 finished with value: 0.8199354317783876 and parameters: {'C': 0.04117060804102329}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:24:32,976] Trial 68 finished with value: 0.8199355832112148 and parameters: {'C': 0.038254176602930894}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:24:35,857] Trial 69 finished with value: 0.8199355832112148 and parameters: {'C': 0.03764736286854547}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:24:38,897] Trial 70 finished with value: 0.8199346162690833 and parameters: {'C': 0.0524492466913286}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:24:41,808] Trial 71 finished with value: 0.8199335040721693 and parameters: {'C': 0.025078729347679813}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:24:44,755] Trial 72 finished with value: 0.8199354448640542 and parameters: {'C': 0.034442636699106806}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:24:47,661] Trial 73 finished with value: 0.8199219938022324 and parameters: {'C': 0.0066197702683462745}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:24:50,538] Trial 74 finished with value: 0.8199351123878283 and parameters: {'C': 0.041664450315331836}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:24:53,698] Trial 75 finished with value: 0.8199339841375981 and parameters: {'C': 0.05452657391298226}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:24:56,776] Trial 76 finished with value: 0.8199349851518004 and parameters: {'C': 0.03301859510049474}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:24:59,725] Trial 77 finished with value: 0.819934993630748 and parameters: {'C': 0.035365284946094165}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:25:02,624] Trial 78 finished with value: 0.8199337980218786 and parameters: {'C': 0.012961585144081113}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:25:05,475] Trial 79 finished with value: 0.8199331628519378 and parameters: {'C': 0.1060193229130872}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:25:08,379] Trial 80 finished with value: 0.8199222691861398 and parameters: {'C': 0.006685992854927051}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:25:11,464] Trial 81 finished with value: 0.8199354337504811 and parameters: {'C': 0.040077852327052695}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:25:14,356] Trial 82 finished with value: 0.8199336664271366 and parameters: {'C': 0.05856585884782338}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:25:17,333] Trial 83 finished with value: 0.8199336125939753 and parameters: {'C': 0.16421087443780968}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:25:20,174] Trial 84 finished with value: 0.8199355832112148 and parameters: {'C': 0.03702474284829873}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:25:23,117] Trial 85 finished with value: 0.8199335676222834 and parameters: {'C': 0.015546265574296328}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:25:26,023] Trial 86 finished with value: 0.819933031009187 and parameters: {'C': 0.07286041900882531}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:25:28,955] Trial 87 finished with value: 0.8199217721114113 and parameters: {'C': 0.006998865232572745}. Best is trial 65 with value: 0.819935714759596.\n",
      "[I 2024-01-06 19:25:31,753] Trial 88 finished with value: 0.8199359045748719 and parameters: {'C': 0.0367514689074616}. Best is trial 88 with value: 0.8199359045748719.\n",
      "[I 2024-01-06 19:25:34,493] Trial 89 finished with value: 0.8199336460752933 and parameters: {'C': 0.025735298145914704}. Best is trial 88 with value: 0.8199359045748719.\n",
      "[I 2024-01-06 19:25:37,568] Trial 90 finished with value: 0.8199336125939753 and parameters: {'C': 0.15730704828529044}. Best is trial 88 with value: 0.8199359045748719.\n",
      "[I 2024-01-06 19:25:40,471] Trial 91 finished with value: 0.8199330293300802 and parameters: {'C': 0.08069583024953361}. Best is trial 88 with value: 0.8199359045748719.\n",
      "[I 2024-01-06 19:25:43,515] Trial 92 finished with value: 0.819934993630748 and parameters: {'C': 0.0356785789464725}. Best is trial 88 with value: 0.8199359045748719.\n",
      "[I 2024-01-06 19:25:46,448] Trial 93 finished with value: 0.8199333914235976 and parameters: {'C': 0.018633798366783694}. Best is trial 88 with value: 0.8199359045748719.\n",
      "[I 2024-01-06 19:25:49,452] Trial 94 finished with value: 0.8199303021419665 and parameters: {'C': 0.00920949967659777}. Best is trial 88 with value: 0.8199359045748719.\n",
      "[I 2024-01-06 19:25:52,445] Trial 95 finished with value: 0.8199336125939753 and parameters: {'C': 0.2600540976011977}. Best is trial 88 with value: 0.8199359045748719.\n",
      "[I 2024-01-06 19:25:55,401] Trial 96 finished with value: 0.8199140857339193 and parameters: {'C': 0.0031618843517039405}. Best is trial 88 with value: 0.8199359045748719.\n",
      "[I 2024-01-06 19:25:58,407] Trial 97 finished with value: 0.8199351140671602 and parameters: {'C': 0.04311490003837821}. Best is trial 88 with value: 0.8199359045748719.\n",
      "[I 2024-01-06 19:26:01,129] Trial 98 finished with value: 0.8199336460752933 and parameters: {'C': 0.02631202637410652}. Best is trial 88 with value: 0.8199359045748719.\n",
      "[I 2024-01-06 19:26:04,033] Trial 99 finished with value: 0.819932711621601 and parameters: {'C': 0.07895862246508611}. Best is trial 88 with value: 0.8199359045748719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-06 19:26:04,035: 92: logger: INFO: common:  json file saved at: logs/LogisticRegression.json]\n",
      "[2024-01-06 19:26:05,981: 136: logger: INFO: stacking_model_training:  Model LogisticRegression has been tuned]\n",
      "[2024-01-06 19:26:05,983: 175: logger: INFO: stacking_model_training:  === FINISHED TRAINING STAGE for stacking models ===]\n",
      "CPU times: user 46.1 s, sys: 26.9 s, total: 1min 12s\n",
      "Wall time: 5min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "component = StackingModelTraining(stacking_model_training_config, config_manager.config.path,\n",
    "                                  models=['LogisticRegression'])\n",
    "component.run_stage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b66c90-ec3e-4671-9e17-6f1069878af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-06 19:28:23,871: 47: logger: INFO: common:  yaml file: src/params/LinearSVC.yaml loaded successfully]\n",
      "[2024-01-06 19:28:23,872: 161: logger: INFO: stacking_model_training:  === STARTING TRAINING STAGE for stacking models ===]\n",
      "[2024-01-06 19:28:23,908: 171: logger: INFO: common:  tensor file has been loaded from: data/target]\n",
      "[2024-01-06 19:28:26,464: 165: logger: INFO: stacking_model_training:  Part1. Target data has been loaded]\n",
      "[2024-01-06 19:28:26,581: 170: logger: INFO: stacking_model_training:  Part2. First level logits have been loaded]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294fbad892d34b829886b7f6563a27d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tuning Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 19:28:26,589] A new study created in memory with name: no-name-60090219-a832-4e51-a77e-d37f5e092a4e\n",
      "[I 2024-01-06 19:28:29,969] Trial 0 finished with value: 0.8206287158794905 and parameters: {'C': 0.017670169402947963}. Best is trial 0 with value: 0.8206287158794905.\n",
      "[I 2024-01-06 19:28:33,292] Trial 1 finished with value: 0.8206302575826185 and parameters: {'C': 50.61576888752309}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:28:36,572] Trial 2 finished with value: 0.8206302575826185 and parameters: {'C': 2.465832945854912}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:28:39,701] Trial 3 finished with value: 0.8206302575826185 and parameters: {'C': 0.39079671568228835}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:28:42,505] Trial 4 finished with value: 0.8206260353610053 and parameters: {'C': 0.0008632008168602544}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:28:45,406] Trial 5 finished with value: 0.8206260353610053 and parameters: {'C': 0.0008629132190071859}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:28:48,239] Trial 6 finished with value: 0.8206269493714767 and parameters: {'C': 0.00022310108018679258}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:28:51,203] Trial 7 finished with value: 0.8206302575826185 and parameters: {'C': 15.741890047456648}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:28:53,996] Trial 8 finished with value: 0.8206302575826185 and parameters: {'C': 0.4042872735027334}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:28:56,752] Trial 9 finished with value: 0.8206302575826185 and parameters: {'C': 1.7718847354806828}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:28:59,577] Trial 10 finished with value: 0.8206302575826185 and parameters: {'C': 75.33019084841482}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:02,396] Trial 11 finished with value: 0.8206302575826185 and parameters: {'C': 7.153293939051241}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:05,160] Trial 12 finished with value: 0.8206302575826185 and parameters: {'C': 74.88122652230464}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:08,046] Trial 13 finished with value: 0.8206297999910217 and parameters: {'C': 0.053539728077986376}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:10,830] Trial 14 finished with value: 0.8206302575826185 and parameters: {'C': 7.099749885151785}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:13,724] Trial 15 finished with value: 0.8206302575826185 and parameters: {'C': 1.3554280409043842}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:16,528] Trial 16 finished with value: 0.8206302575826185 and parameters: {'C': 21.555185438491794}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:19,318] Trial 17 finished with value: 0.8206276574022835 and parameters: {'C': 0.012385420496245022}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:22,228] Trial 18 finished with value: 0.8206302575826185 and parameters: {'C': 2.2785003542887967}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:25,092] Trial 19 finished with value: 0.8206302575826185 and parameters: {'C': 0.29384604688430443}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:27,967] Trial 20 finished with value: 0.8206302575826185 and parameters: {'C': 36.282639783793606}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:30,772] Trial 21 finished with value: 0.8206302575826185 and parameters: {'C': 0.2374558899032105}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:33,478] Trial 22 finished with value: 0.8206302575826185 and parameters: {'C': 4.82182267327548}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:36,247] Trial 23 finished with value: 0.8206302575826185 and parameters: {'C': 0.07706666720219976}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:38,943] Trial 24 finished with value: 0.8206302575826185 and parameters: {'C': 0.630871095517034}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:41,719] Trial 25 finished with value: 0.8206302575826185 and parameters: {'C': 0.8257841207383289}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:44,613] Trial 26 finished with value: 0.820629339584634 and parameters: {'C': 0.022373718952572622}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:47,465] Trial 27 finished with value: 0.8206302575826185 and parameters: {'C': 4.034186634482999}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:50,277] Trial 28 finished with value: 0.8206302575826185 and parameters: {'C': 0.1600387115225054}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:53,050] Trial 29 finished with value: 0.8206302575826185 and parameters: {'C': 16.053540616106904}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:55,868] Trial 30 finished with value: 0.8206297999910217 and parameters: {'C': 0.0318520117525409}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:29:58,667] Trial 31 finished with value: 0.8206302575826185 and parameters: {'C': 15.078628548167408}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:01,391] Trial 32 finished with value: 0.8206302575826185 and parameters: {'C': 34.442091239692516}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:04,213] Trial 33 finished with value: 0.820629916221352 and parameters: {'C': 0.00443516559548524}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:06,943] Trial 34 finished with value: 0.8206302575826185 and parameters: {'C': 10.30827152499306}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:09,757] Trial 35 finished with value: 0.8206302575826185 and parameters: {'C': 3.306331267262611}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:12,632] Trial 36 finished with value: 0.8206302575826185 and parameters: {'C': 95.17928823600522}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:15,340] Trial 37 finished with value: 0.8206302575826185 and parameters: {'C': 1.104548763058091}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:18,117] Trial 38 finished with value: 0.8206302575826185 and parameters: {'C': 29.99665666344999}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:20,849] Trial 39 finished with value: 0.8206302575826185 and parameters: {'C': 0.5385957985690705}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:23,611] Trial 40 finished with value: 0.8206302575826185 and parameters: {'C': 48.24055150345883}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:26,400] Trial 41 finished with value: 0.8206302575826185 and parameters: {'C': 0.43549118289042027}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:29,204] Trial 42 finished with value: 0.8206302575826185 and parameters: {'C': 1.8453115688819348}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:32,008] Trial 43 finished with value: 0.8206302575826185 and parameters: {'C': 0.16374191007185931}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:34,782] Trial 44 finished with value: 0.8206302575826185 and parameters: {'C': 11.584588462259234}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:37,520] Trial 45 finished with value: 0.8206302575826185 and parameters: {'C': 6.648956684011114}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:40,232] Trial 46 finished with value: 0.8206302575826185 and parameters: {'C': 2.7368966000320287}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:43,002] Trial 47 finished with value: 0.8206231603698182 and parameters: {'C': 0.000423305573403652}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:45,794] Trial 48 finished with value: 0.8206302575826185 and parameters: {'C': 55.67652683573019}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:48,651] Trial 49 finished with value: 0.8206302575826185 and parameters: {'C': 1.236657927486433}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:51,414] Trial 50 finished with value: 0.8206302575826185 and parameters: {'C': 0.08517044718857586}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:54,162] Trial 51 finished with value: 0.8206302575826185 and parameters: {'C': 0.269796600659716}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:56,934] Trial 52 finished with value: 0.8206302575826185 and parameters: {'C': 1.9417891526622821}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:30:59,728] Trial 53 finished with value: 0.8206302575826185 and parameters: {'C': 5.492804364782054}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:02,611] Trial 54 finished with value: 0.8206302575826185 and parameters: {'C': 0.41983848883523267}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:05,406] Trial 55 finished with value: 0.8206302575826185 and parameters: {'C': 0.8652820532887742}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:08,259] Trial 56 finished with value: 0.8206302575826185 and parameters: {'C': 0.15327253054254614}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:11,035] Trial 57 finished with value: 0.8206286566989006 and parameters: {'C': 0.005934715653256226}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:13,841] Trial 58 finished with value: 0.8206195432514647 and parameters: {'C': 0.00011639521730508292}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:16,635] Trial 59 finished with value: 0.8206302575826185 and parameters: {'C': 18.648583947479736}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:19,715] Trial 60 finished with value: 0.8206297999910217 and parameters: {'C': 0.04963351209925458}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:22,541] Trial 61 finished with value: 0.8206302575826185 and parameters: {'C': 71.87228177135553}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:25,348] Trial 62 finished with value: 0.8206302575826185 and parameters: {'C': 28.075272224771638}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:28,182] Trial 63 finished with value: 0.8206302575826185 and parameters: {'C': 95.40591720154524}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:31,037] Trial 64 finished with value: 0.8206302575826185 and parameters: {'C': 7.832924912850443}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:33,863] Trial 65 finished with value: 0.8206302575826185 and parameters: {'C': 49.81161441265658}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:36,715] Trial 66 finished with value: 0.8206302575826185 and parameters: {'C': 3.3730232586710414}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:39,517] Trial 67 finished with value: 0.8206302575826185 and parameters: {'C': 22.68342117071045}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:42,273] Trial 68 finished with value: 0.8206302575826185 and parameters: {'C': 11.046460663472573}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:45,049] Trial 69 finished with value: 0.8206302575826185 and parameters: {'C': 2.099480345001735}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:47,953] Trial 70 finished with value: 0.8206302575826185 and parameters: {'C': 0.9242268174079391}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:50,694] Trial 71 finished with value: 0.8206302575826185 and parameters: {'C': 4.581644040760798}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:53,464] Trial 72 finished with value: 0.8206302575826185 and parameters: {'C': 1.4829874513125791}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:56,214] Trial 73 finished with value: 0.8206302575826185 and parameters: {'C': 37.31940016934474}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:31:59,046] Trial 74 finished with value: 0.8206302575826185 and parameters: {'C': 15.333867709024215}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:01,770] Trial 75 finished with value: 0.8206302575826185 and parameters: {'C': 8.812507127738922}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:04,557] Trial 76 finished with value: 0.8206302575826185 and parameters: {'C': 0.6120098629090515}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:07,346] Trial 77 finished with value: 0.8206302575826185 and parameters: {'C': 0.3647484360237938}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:10,204] Trial 78 finished with value: 0.8206302575826185 and parameters: {'C': 23.78068315208161}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:13,075] Trial 79 finished with value: 0.8206302575826185 and parameters: {'C': 3.157050140077289}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:15,858] Trial 80 finished with value: 0.8206302575826185 and parameters: {'C': 0.20719763201972055}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:18,683] Trial 81 finished with value: 0.8206302575826185 and parameters: {'C': 68.08555415680863}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:21,517] Trial 82 finished with value: 0.8206302575826185 and parameters: {'C': 44.47402117137427}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:24,248] Trial 83 finished with value: 0.8206302575826185 and parameters: {'C': 13.670504565754063}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:27,102] Trial 84 finished with value: 0.8206302575826185 and parameters: {'C': 5.541737579505976}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:29,841] Trial 85 finished with value: 0.8206302575826185 and parameters: {'C': 63.955592763307266}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:32,708] Trial 86 finished with value: 0.8206302575826185 and parameters: {'C': 30.179266087298522}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:35,504] Trial 87 finished with value: 0.8206302575826185 and parameters: {'C': 0.11558371037205989}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:38,393] Trial 88 finished with value: 0.8206302575826185 and parameters: {'C': 1.4569655623756523}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:41,153] Trial 89 finished with value: 0.8206302575826185 and parameters: {'C': 7.239555534046672}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:43,957] Trial 90 finished with value: 0.8206302575826185 and parameters: {'C': 88.35361092982556}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:46,726] Trial 91 finished with value: 0.8206302575826185 and parameters: {'C': 18.46086077542651}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:49,560] Trial 92 finished with value: 0.8206302575826185 and parameters: {'C': 4.363302719014182}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:52,448] Trial 93 finished with value: 0.8206302575826185 and parameters: {'C': 2.598794211446146}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:55,266] Trial 94 finished with value: 0.8206302575826185 and parameters: {'C': 10.080070427381118}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:32:57,996] Trial 95 finished with value: 0.8206302575826185 and parameters: {'C': 39.43519563940834}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:33:00,743] Trial 96 finished with value: 0.8206302575826185 and parameters: {'C': 23.59892930083902}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:33:03,559] Trial 97 finished with value: 0.8206302575826185 and parameters: {'C': 6.621211923531219}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:33:06,467] Trial 98 finished with value: 0.8206302575826185 and parameters: {'C': 0.6577264761715071}. Best is trial 1 with value: 0.8206302575826185.\n",
      "[I 2024-01-06 19:33:09,422] Trial 99 finished with value: 0.8206297999910217 and parameters: {'C': 0.05100438528983189}. Best is trial 1 with value: 0.8206302575826185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-06 19:33:09,424: 92: logger: INFO: common:  json file saved at: logs/LinearSVC.json]\n",
      "[2024-01-06 19:33:11,073: 136: logger: INFO: stacking_model_training:  Model LinearSVC has been tuned]\n",
      "[2024-01-06 19:33:11,074: 175: logger: INFO: stacking_model_training:  === FINISHED TRAINING STAGE for stacking models ===]\n",
      "CPU times: user 39.2 s, sys: 10.4 s, total: 49.6 s\n",
      "Wall time: 4min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "component = StackingModelTraining(stacking_model_training_config, config_manager.config.path,\n",
    "                                  models=['LinearSVC'])\n",
    "component.run_stage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8654b49e-dc22-4a63-8e5f-bac7ffc7e1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-06 18:49:14,895: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiRNN_0.json]\n",
      "[2024-01-06 18:49:14,898: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiRNN_1.json]\n",
      "[2024-01-06 18:49:14,899: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiRNN_2.json]\n",
      "[2024-01-06 18:49:14,901: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiRNN_3.json]\n",
      "[2024-01-06 18:49:14,902: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiLSTM_0.json]\n",
      "[2024-01-06 18:49:14,904: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiLSTM_1.json]\n",
      "[2024-01-06 18:49:14,906: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiLSTM_2.json]\n",
      "[2024-01-06 18:49:14,907: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiLSTM_3.json]\n",
      "[2024-01-06 18:49:14,909: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_GRU_0.json]\n",
      "[2024-01-06 18:49:14,910: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_GRU_1.json]\n",
      "[2024-01-06 18:49:14,911: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_GRU_2.json]\n",
      "[2024-01-06 18:49:14,912: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_GRU_3.json]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MHSA_STCNN_BiRNN': 0.810941351117021,\n",
       " 'MHSA_STCNN_BiLSTM': 0.8187692326721039,\n",
       " 'MHSA_STCNN_GRU': 0.8133850453813676}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from src.utils.common import load_json\n",
    "\n",
    "scores = {}\n",
    "models = ['MHSA_STCNN_BiRNN', 'MHSA_STCNN_BiLSTM', 'MHSA_STCNN_GRU']\n",
    "metric = 'f1_neg'\n",
    "for model in models:\n",
    "    scores[model] = np.mean([load_json(Path(os.path.join('logs', f'{model}_{it}.json')))[metric] for it in range(4)])\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce3e8d22-2aa0-43cd-af23-436f2e773339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-06 17:51:10,820: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiRNN_0.json]\n",
      "[2024-01-06 17:51:10,822: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiRNN_1.json]\n",
      "[2024-01-06 17:51:10,822: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiRNN_2.json]\n",
      "[2024-01-06 17:51:10,824: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiRNN_3.json]\n",
      "[2024-01-06 17:51:10,825: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiLSTM_0.json]\n",
      "[2024-01-06 17:51:10,826: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiLSTM_1.json]\n",
      "[2024-01-06 17:51:10,827: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiLSTM_2.json]\n",
      "[2024-01-06 17:51:10,828: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_BiLSTM_3.json]\n",
      "[2024-01-06 17:51:10,829: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_GRU_0.json]\n",
      "[2024-01-06 17:51:10,830: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_GRU_1.json]\n",
      "[2024-01-06 17:51:10,831: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_GRU_2.json]\n",
      "[2024-01-06 17:51:10,832: 116: logger: INFO: common:  json file loaded successfully from: logs/MHSA_STCNN_GRU_3.json]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MHSA_STCNN_BiRNN': 0.8867591562503392,\n",
       " 'MHSA_STCNN_BiLSTM': 0.8887787985913108,\n",
       " 'MHSA_STCNN_GRU': 0.8882525264469857}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from src.utils.common import load_json\n",
    "\n",
    "scores = {}\n",
    "models = ['MHSA_STCNN_BiRNN', 'MHSA_STCNN_BiLSTM', 'MHSA_STCNN_GRU']\n",
    "metric = 'f1_neg'\n",
    "for model in models:\n",
    "    scores[model] = np.mean([load_json(Path(os.path.join('logs', f'{model}_{it}.json')))[metric] for it in range(4)])\n",
    "\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
